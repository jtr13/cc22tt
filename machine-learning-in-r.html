<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 51 Machine Learning in R | Community Contributions for EDAV Fall 2022 Tues/Thurs</title>
<meta name="description" content="Wanling Bai and Yancheng Zhang # load packages library(class) library(rpart) library('NbClust') # install_github(&quot;vqv/ggbiplot&quot;) library(ggbiplot)  51.1 1. Contribution We’ve learned exploratory...">
<meta name="generator" content="bookdown 0.30 with bs4_book()">
<meta property="og:title" content="Chapter 51 Machine Learning in R | Community Contributions for EDAV Fall 2022 Tues/Thurs">
<meta property="og:type" content="book">
<meta property="og:description" content="Wanling Bai and Yancheng Zhang # load packages library(class) library(rpart) library('NbClust') # install_github(&quot;vqv/ggbiplot&quot;) library(ggbiplot)  51.1 1. Contribution We’ve learned exploratory...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 51 Machine Learning in R | Community Contributions for EDAV Fall 2022 Tues/Thurs">
<meta name="twitter:description" content="Wanling Bai and Yancheng Zhang # load packages library(class) library(rpart) library('NbClust') # install_github(&quot;vqv/ggbiplot&quot;) library(ggbiplot)  51.1 1. Contribution We’ve learned exploratory...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.1/transition.js"></script><script src="libs/bs3compat-0.4.1/tabs.js"></script><script src="libs/bs3compat-0.4.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/plotly-binding-4.10.1/plotly.js"></script><script src="libs/typedarray-0.1/typedarray.min.js"></script><link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script><link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script><link href="libs/visjs-7.4.9/vis-timeline-graph2d.min.css" rel="stylesheet">
<script src="libs/visjs-7.4.9/vis-timeline-graph2d.min.js"></script><link href="libs/timeline-0.4/timevis.css" rel="stylesheet">
<script src="libs/timevis-binding-2.1.0/timevis.js"></script><link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet">
<script src="libs/leaflet-1.3.1/leaflet.js"></script><link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet">
<script src="libs/proj4-2.6.2/proj4.min.js"></script><script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script><link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet">
<script src="libs/leaflet-binding-2.1.1/leaflet.js"></script><link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet">
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script><script src="libs/dygraphs-1.1.1/shapes.js"></script><script src="libs/moment-2.8.4/moment.js"></script><script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script><script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script><script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script><script src="libs/Dygraph.Plugins.Crosshair-1.0/crosshair.js"></script><link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="libs/datatables-binding-0.26/datatables.js"></script><link href="libs/dt-core-1.12.1/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="libs/dt-core-1.12.1/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="libs/dt-core-1.12.1/js/jquery.dataTables.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Community Contributions for EDAV Fall 2022 Tues/Thurs</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Welcome!</a></li>
<li><a class="" href="community-contribution.html"><span class="header-section-number">2</span> Community Contribution</a></li>
<li><a class="" href="github-submission-instructions.html"><span class="header-section-number">3</span> GitHub submission instructions</a></li>
<li><a class="" href="sample-project.html"><span class="header-section-number">4</span> Sample project</a></li>
<li class="book-part">Cheatsheets</li>
<li><a class="" href="r-window-functions-cheatsheet.html"><span class="header-section-number">6</span> R window functions cheatsheet</a></li>
<li><a class="" href="rmd-chunk-option-cheat-sheet.html"><span class="header-section-number">7</span> Rmd chunk option cheat sheet</a></li>
<li><a class="" href="helpful-ggplot2-extensions-cheatsheet.html"><span class="header-section-number">8</span> Helpful ggplot2 Extensions Cheatsheet</a></li>
<li><a class="" href="commonly-used-graph-cheatcheet.html"><span class="header-section-number">9</span> Commonly-used graph cheatcheet</a></li>
<li><a class="" href="git-and-version-control.html"><span class="header-section-number">10</span> Git and version control</a></li>
<li><a class="" href="useful-plots-for-bioinfomatics-in-r.html"><span class="header-section-number">11</span> Useful plots for Bioinfomatics in R</a></li>
<li><a class="" href="different-ways-to-create-world-map-in-r.html"><span class="header-section-number">12</span> Different ways to create world map in R</a></li>
<li><a class="" href="color-in-r-python-and-jshtmlcss.html"><span class="header-section-number">13</span> Color in R, Python, and JS/HTML/CSS</a></li>
<li><a class="" href="color-palettes-for-data-visualization.html"><span class="header-section-number">14</span> Color Palettes for Data Visualization</a></li>
<li><a class="" href="data-visualization-using-seaborn.html"><span class="header-section-number">15</span> Data visualization using Seaborn</a></li>
<li><a class="" href="machine-learning-cheatsheet-for-r-and-python.html"><span class="header-section-number">16</span> Machine Learning Cheatsheet for R and Python</a></li>
<li><a class="" href="data-visualization-with-r-ggplot2-vs.-matlab.html"><span class="header-section-number">17</span> Data Visualization with R ggplot2 vs. Matlab</a></li>
<li><a class="" href="ggplot2-plots-in-python-cheat-sheet-tutorial.html"><span class="header-section-number">18</span> Ggplot2 plots in python cheat sheet tutorial</a></li>
<li><a class="" href="model-evaluation-selection-visualization-with-easystats.html"><span class="header-section-number">19</span> Model evaluation, selection &amp; visualization with easystats</a></li>
<li><a class="" href="time-series-itsmr-cheat-sheet.html"><span class="header-section-number">20</span> Time Series: ITSMR Cheat Sheet</a></li>
<li class="book-part">Tutorials</li>
<li><a class="" href="preprocessing-and-visualization-of-time-series-data.html"><span class="header-section-number">22</span> Preprocessing and Visualization of Time Series Data</a></li>
<li><a class="" href="how-to-use-sqldf.html"><span class="header-section-number">23</span> How to use sqldf</a></li>
<li><a class="" href="googlevis-in-r.html"><span class="header-section-number">24</span> googleVis in R</a></li>
<li><a class="" href="tutorial-for-vector-fields-in-r.html"><span class="header-section-number">25</span> Tutorial for vector fields in r</a></li>
<li><a class="" href="data-cleaning-with-r.html"><span class="header-section-number">26</span> Data cleaning with r</a></li>
<li><a class="" href="introduction-to-shiny-web-apps.html"><span class="header-section-number">27</span> Introduction to Shiny Web Apps</a></li>
<li><a class="" href="python-missingno-library-tutorial.html"><span class="header-section-number">28</span> Python missingno library tutorial</a></li>
<li><a class="" href="data-explorer-tutorial-and-automation.html"><span class="header-section-number">29</span> Data Explorer Tutorial and Automation</a></li>
<li><a class="" href="d-visualization-in-r.html"><span class="header-section-number">30</span> 3D Visualization in R</a></li>
<li><a class="" href="visualizing-time-series-data.html"><span class="header-section-number">31</span> Visualizing Time Series Data</a></li>
<li><a class="" href="igraph-in-r.html"><span class="header-section-number">32</span> igraph in r</a></li>
<li><a class="" href="geo-mapping-coordinate-extraction-using-api-calls.html"><span class="header-section-number">33</span> Geo-Mapping Coordinate Extraction Using API Calls</a></li>
<li><a class="" href="edav-garden.html"><span class="header-section-number">34</span> EDAV Garden</a></li>
<li><a class="" href="using-raster-data-in-r.html"><span class="header-section-number">35</span> Using raster data in R</a></li>
<li><a class="" href="make-geographical-maps-with-different-packages.html"><span class="header-section-number">36</span> Make Geographical Maps with Different Packages</a></li>
<li><a class="" href="how-to-obtain-data-from-api-and-process-raw-json-data.html"><span class="header-section-number">37</span> How to obtain data from API and process raw JSON data</a></li>
<li><a class="" href="sample-statistic-tutorial.html"><span class="header-section-number">38</span> Sample Statistic Tutorial</a></li>
<li><a class="" href="data-cleaning-tutorial.html"><span class="header-section-number">39</span> Data cleaning tutorial</a></li>
<li><a class="" href="mlr3-package-tutorial.html"><span class="header-section-number">40</span> mlr3 Package Tutorial</a></li>
<li><a class="" href="guide-to-nonparametric-tests.html"><span class="header-section-number">41</span> Guide to nonparametric tests</a></li>
<li><a class="" href="dplyr-pacakage-in-r.html"><span class="header-section-number">42</span> dplyr pacakage in R</a></li>
<li><a class="" href="how-not-to-visualize-american-elections.html"><span class="header-section-number">43</span> How (not) to visualize American elections</a></li>
<li><a class="" href="time-series-visualization-with-r.html"><span class="header-section-number">44</span> Time series visualization with R</a></li>
<li><a class="" href="twitter-textual-data-scraping-and-analyzing.html"><span class="header-section-number">45</span> Twitter textual data: scraping and analyzing</a></li>
<li><a class="" href="causal-inference-tutorial-a-quick-glance-at-interventional-treatment-and-simpsons-paradox.html"><span class="header-section-number">46</span> Causal Inference Tutorial: A Quick Glance at Interventional Treatment and Simpson’s Paradox</a></li>
<li><a class="" href="network-analysis-and-social-network-analysis.html"><span class="header-section-number">47</span> Network analysis and social network analysis</a></li>
<li><a class="" href="network-analysis-in-r.html"><span class="header-section-number">48</span> Network Analysis in R</a></li>
<li><a class="" href="interactive-3d-visualization-in-r.html"><span class="header-section-number">49</span> Interactive 3D Visualization in R</a></li>
<li><a class="" href="introduction-to-common-sampling-techniques-in-r.html"><span class="header-section-number">50</span> Introduction to common sampling techniques in r</a></li>
<li><a class="active" href="machine-learning-in-r.html"><span class="header-section-number">51</span> Machine Learning in R</a></li>
<li><a class="" href="what-you-see-is-what-you-understand-learning-data-science-visually.html"><span class="header-section-number">52</span> What you see is what you understand: learning data science visually</a></li>
<li><a class="" href="is-the-data-visualization-misleading-or-not---survey.html"><span class="header-section-number">53</span> Is the data visualization misleading or not - Survey</a></li>
<li><a class="" href="animating-functions-and-histograms-in-python-using-matplotlib.html"><span class="header-section-number">54</span> Animating functions and histograms in python using matplotlib</a></li>
<li><a class="" href="waterfall-chart-using-meta-income-statement.html"><span class="header-section-number">55</span> Waterfall chart using meta income statement</a></li>
<li class="book-part">Interview Prep</li>
<li><a class="" href="ten-interview-questions-and-answers.html"><span class="header-section-number">57</span> Ten interview questions and answers</a></li>
<li><a class="" href="data-science-internship-search-survival-guide.html"><span class="header-section-number">58</span> Data science internship search survival guide</a></li>
<li><a class="" href="data-visualization-interview-questions-sample.html"><span class="header-section-number">59</span> Data visualization interview questions sample</a></li>
<li><a class="" href="how-i-got-into-amazon-as-a-full-time-data-analyst.html"><span class="header-section-number">60</span> How I got into Amazon as a full time data analyst</a></li>
<li class="book-part">Case Studies</li>
<li><a class="" href="benford-case-study.html"><span class="header-section-number">62</span> Benford Case Study</a></li>
<li class="book-part">Blogs</li>
<li><a class="" href="equity-in-ai.html"><span class="header-section-number">64</span> Equity in AI</a></li>
<li><a class="" href="breaking-into-tech-black-girl-edition.html"><span class="header-section-number">65</span> Breaking into tech: black girl edition</a></li>
<li><a class="" href="homepage-artwork.html"><span class="header-section-number">66</span> Homepage Artwork</a></li>
<li><a class="" href="design-homepage-for-class-community.html"><span class="header-section-number">67</span> Design homepage for class community</a></li>
<li class="book-part">Appendices</li>
<li><a class="" href="github-initial-setup.html"><span class="header-section-number">68</span> Github initial setup</a></li>
<li><a class="" href="tutorial-for-pull-request-mergers.html"><span class="header-section-number">69</span> Tutorial for pull request mergers</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/jtr13/cc22tt">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="machine-learning-in-r" class="section level1" number="51">
<h1>
<span class="header-section-number">51</span> Machine Learning in R<a class="anchor" aria-label="anchor" href="#machine-learning-in-r"><i class="fas fa-link"></i></a>
</h1>
<p>Wanling Bai and Yancheng Zhang</p>
<div class="sourceCode" id="cb810"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># load packages</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">class</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/bethatkinson/rpart">rpart</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://sites.google.com/site/malikacharrad/research/nbclust-package">'NbClust'</a></span><span class="op">)</span></span>
<span><span class="co"># install_github("vqv/ggbiplot")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://github.com/vqv/ggbiplot">ggbiplot</a></span><span class="op">)</span></span></code></pre></div>
<div id="contribution" class="section level2" number="51.1">
<h2>
<span class="header-section-number">51.1</span> 1. Contribution<a class="anchor" aria-label="anchor" href="#contribution"><i class="fas fa-link"></i></a>
</h2>
<p>We’ve learned exploratory data analysis and visualization in R. It is naturally for us to explore the next step for data analyze: machine learning. Since loading data from one platform to another can be time-costing, doing data analyze in one platform simplify our work flow and improve efficiency.</p>
<p>Unlike Python, different machine learning methods are in different R packages. Some machines learning models are implemented with certain parameter in the functions. If we change the parameter, we change the method. Finding the packages and the right parameter for machine learning methods can be laborious. For this tutorial, we go through some machine learning methods with brief description, pros and cons, and application examples. By composing this tutorial, we gain a systematic knowledge of how to implement machine learning in R and experience the difference between platforms. Hopefully, this tutorial can help you get start with machine learning in R.</p>
</div>
<div id="evaluation-3" class="section level2" number="51.2">
<h2>
<span class="header-section-number">51.2</span> 2. Evaluation<a class="anchor" aria-label="anchor" href="#evaluation-3"><i class="fas fa-link"></i></a>
</h2>
<p>We learned how to process Machine Learning in R, especially how to interpret the corresponding parameters when using functions. However, in this tutorial we just explained “Supervised Machine Learning” and “Unsupervised Machine Learning”, there are also other models/methods such as meta-algorithms, time series models, model validation and etc. For further improvements, we can add these parts to tutorial and make it more straightforward to beginners to perform Machine Learning in R.</p>
</div>
<div id="supervised-learning-in-r" class="section level2" number="51.3">
<h2>
<span class="header-section-number">51.3</span> 3. Supervised Learning in R<a class="anchor" aria-label="anchor" href="#supervised-learning-in-r"><i class="fas fa-link"></i></a>
</h2>
<div id="linear-regression" class="section level3" number="51.3.1">
<h3>
<span class="header-section-number">51.3.1</span> 3.1 Linear Regression<a class="anchor" aria-label="anchor" href="#linear-regression"><i class="fas fa-link"></i></a>
</h3>
<p>Linear regression fits a linear relationship between inputs and a numerical output.</p>
<p>To implement linear regression in R, use function ‘lm()’ in package ‘stats’.</p>
<p>Reference:
<a href="https://www.edureka.co/blog/linear-regression-for-machine-learning/" class="uri">https://www.edureka.co/blog/linear-regression-for-machine-learning/</a></p>
<p><strong>Linear Regression Advantages: </strong><br>
1. Easy to train and interpret<br>
2. Handles overfitting well using dimensional reduction techniques, regularization, and cross-validation<br>
3. Can increase model flexible with modifications that don’t affect estimation</p>
<p><strong>Linear Regression Disadvantages: </strong><br>
1. The assumption of linearity between input and output variables does not always hold<br>
2. Sensitive to outliers<br>
3. Prone to multicollinearity</p>
<p>Reference:
<a href="https://www.tutorialspoint.com/r/r_linear_regression.htm" class="uri">https://www.tutorialspoint.com/r/r_linear_regression.htm</a></p>
<div class="sourceCode" id="cb811"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">151</span>, <span class="fl">174</span>, <span class="fl">138</span>, <span class="fl">186</span>, <span class="fl">128</span>, <span class="fl">136</span>, <span class="fl">179</span>, <span class="fl">163</span>, <span class="fl">152</span>, <span class="fl">131</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">63</span>, <span class="fl">81</span>, <span class="fl">56</span>, <span class="fl">91</span>, <span class="fl">47</span>, <span class="fl">57</span>, <span class="fl">76</span>, <span class="fl">72</span>, <span class="fl">62</span>, <span class="fl">48</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># fit the model</span></span>
<span><span class="va">relation</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span><span class="op">~</span><span class="va">x</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">relation</span><span class="op">)</span><span class="op">)</span> <span class="co"># 'lm()' returns an object of class 'lm'</span></span></code></pre></div>
<pre><code>## [1] "lm"</code></pre>
<div class="sourceCode" id="cb813"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">relation</span><span class="op">)</span> </span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Coefficients:
## (Intercept)            x  
##    -38.4551       0.6746</code></pre>
<div class="sourceCode" id="cb815"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># interpret the model and see accuracy</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">relation</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.3002 -1.6629  0.0412  1.8944  3.9775 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -38.45509    8.04901  -4.778  0.00139 ** 
## x             0.67461    0.05191  12.997 1.16e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.253 on 8 degrees of freedom
## Multiple R-squared:  0.9548, Adjusted R-squared:  0.9491 
## F-statistic: 168.9 on 1 and 8 DF,  p-value: 1.164e-06</code></pre>
<div class="sourceCode" id="cb817"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">'prediction:'</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] "prediction:"</code></pre>
<div class="sourceCode" id="cb819"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">170</span><span class="op">)</span> <span class="co"># new inpput data </span></span>
<span><span class="co"># predict with new input data</span></span>
<span><span class="va">result</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">relation</span>,<span class="va">a</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<pre><code>##        1 
## 76.22869</code></pre>
</div>
<div id="logistic-regression" class="section level3" number="51.3.2">
<h3>
<span class="header-section-number">51.3.2</span> 3.2 Logistic Regression<a class="anchor" aria-label="anchor" href="#logistic-regression"><i class="fas fa-link"></i></a>
</h3>
<p>Logistic regression fits a linear relationship between inputs and a categorical output.</p>
<p>To implement logistic regression in R, use function ‘glm()’ in package ‘stats’.</p>
<p><strong>Logistic Regression Advantages: </strong><br>
1. Easy to train and interpret<br>
2. Handles overfitting well using dimensional reduction techniques, regularization, and cross-validation<br>
3. Can increase model flexible with modifications that don’t affect estimation</p>
<p><strong>Logistic Regression Disadvantages: </strong><br>
1. The assumption of linearity between input and output variables does not always hold and is hard to check<br>
2. Can overfit with small, high-dimensional data</p>
<p>Reference:
<a href="https://www.tutorialspoint.com/r/r_logistic_regression.htm" class="uri">https://www.tutorialspoint.com/r/r_logistic_regression.htm</a></p>
<div class="sourceCode" id="cb821"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">input</span> <span class="op">&lt;-</span> <span class="va">mtcars</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"am"</span>,<span class="st">"cyl"</span>,<span class="st">"hp"</span>,<span class="st">"wt"</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co"># fit the model</span></span>
<span><span class="va">am.data</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">am</span> <span class="op">~</span> <span class="va">cyl</span> <span class="op">+</span> <span class="va">hp</span> <span class="op">+</span> <span class="va">wt</span>, data <span class="op">=</span> <span class="va">input</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span> </span>
<span><span class="co"># formula expression am ~ cyl + hp + wt specifies the model</span></span>
<span><span class="co"># interpret the model and see accuracy</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">am.data</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = am ~ cyl + hp + wt, family = binomial, data = input)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.17272  -0.14907  -0.01464   0.14116   1.27641  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept) 19.70288    8.11637   2.428   0.0152 *
## cyl          0.48760    1.07162   0.455   0.6491  
## hp           0.03259    0.01886   1.728   0.0840 .
## wt          -9.14947    4.15332  -2.203   0.0276 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 43.2297  on 31  degrees of freedom
## Residual deviance:  9.8415  on 28  degrees of freedom
## AIC: 17.841
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<div class="sourceCode" id="cb823"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">'prediction:'</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] "prediction:"</code></pre>
<div class="sourceCode" id="cb825"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># predict </span></span>
<span><span class="va">result</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">am.data</span>,<span class="va">input</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<pre><code>##           Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive 
##          2.24194025         -0.09117492          3.45752720         -3.20199515 
##   Hornet Sportabout             Valiant          Duster 360           Merc 240D 
##         -2.16697131         -5.60657399         -1.07498527         -5.51285476 
##            Merc 230            Merc 280           Merc 280C          Merc 450SE 
##         -4.07135061         -4.83693440         -4.83693440         -7.76817983 
##          Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental 
##         -4.65735960         -5.11483316        -17.74976403        -19.01585528 
##   Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla 
##        -17.80417191          3.67548850          8.57164573          6.98245384 
##       Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28 
##          2.26122057         -3.71372091         -2.93601585         -3.54534251 
##    Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa 
##         -5.87250717          6.10009839          5.03924867         11.49298403 
##      Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E 
##          3.20404508          2.98797849          1.85826556         -0.22976277</code></pre>
</div>
<div id="k-nearest-neighboors" class="section level3" number="51.3.3">
<h3>
<span class="header-section-number">51.3.3</span> 3.3 k-Nearest Neighboors<a class="anchor" aria-label="anchor" href="#k-nearest-neighboors"><i class="fas fa-link"></i></a>
</h3>
<p>KNN which stand for K Nearest Neighbor, is a Supervised Machine Learning algorithm that classifies a new data point into the target class, depending on the features of its neighboring data points.</p>
<p>To use KNN algorithm in R, we must first install the ‘class’ package provided by R. This package has the KNN function in it.</p>
<p>Success and failure modes for KNN:</p>
<p><strong>KNN generally performs well when:</strong></p>
<ul>
<li>the data are concentrated in the feature space</li>
<li>the classes appear in separable clusters</li>
</ul>
<p><strong>KNN generally performs poorly when:</strong></p>
<ul>
<li>the feature space is high-dimensional (many predictors)</li>
<li>there are superfluous features (unrelated to calss membreships)</li>
</ul>
<p>Reference:</p>
<p><a href="https://www.edureka.co/blog/knn-algorithm-in-r/" class="uri">https://www.edureka.co/blog/knn-algorithm-in-r/</a></p>
<div class="sourceCode" id="cb827"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/warnings.html">warnings</a></span><span class="op">(</span><span class="st">'off'</span><span class="op">)</span></span>
<span><span class="co"># install.packages('class')       #Install class package</span></span>
<span><span class="co"># library(class)                    # Load class package</span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">iris3</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">25</span>,,<span class="fl">1</span><span class="op">]</span>, <span class="va">iris3</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">25</span>,,<span class="fl">2</span><span class="op">]</span>, <span class="va">iris3</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">25</span>,,<span class="fl">3</span><span class="op">]</span><span class="op">)</span>    <span class="co"># X_train</span></span>
<span><span class="va">test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">iris3</span><span class="op">[</span><span class="fl">26</span><span class="op">:</span><span class="fl">50</span>,,<span class="fl">1</span><span class="op">]</span>, <span class="va">iris3</span><span class="op">[</span><span class="fl">26</span><span class="op">:</span><span class="fl">50</span>,,<span class="fl">2</span><span class="op">]</span>, <span class="va">iris3</span><span class="op">[</span><span class="fl">26</span><span class="op">:</span><span class="fl">50</span>,,<span class="fl">3</span><span class="op">]</span><span class="op">)</span>  <span class="co"># X_test</span></span>
<span><span class="va">cl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"s"</span>,<span class="fl">25</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"c"</span>,<span class="fl">25</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"v"</span>,<span class="fl">25</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>            <span class="co"># y_train</span></span>
<span><span class="va">cl_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"s"</span>,<span class="fl">25</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"c"</span>,<span class="fl">25</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"v"</span>,<span class="fl">25</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>       <span class="co"># y_test</span></span>
<span><span class="va">cl_hat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/class/man/knn.html">knn</a></span><span class="op">(</span><span class="va">train</span>, <span class="va">test</span>, <span class="va">cl</span>, k <span class="op">=</span> <span class="fl">3</span>, prob<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span>                   <span class="co"># k: 'k' in KNN model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">cl_hat</span><span class="op">)</span>                                                       <span class="co"># Output</span></span></code></pre></div>
<pre><code>##  Factor w/ 3 levels "c","s","v": 2 2 2 2 2 2 2 2 2 2 ...
##  - attr(*, "prob")= num [1:75] 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="sourceCode" id="cb829"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">cl_test</span>, <span class="va">cl_hat</span><span class="op">)</span>                                            <span class="co"># cross-tabulate</span></span></code></pre></div>
<pre><code>##        cl_hat
## cl_test  c  s  v
##       c 23  0  2
##       s  0 25  0
##       v  4  0 21</code></pre>
<div class="sourceCode" id="cb831"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">cl_test</span> <span class="op">!=</span> <span class="va">cl_hat</span><span class="op">)</span>                                           <span class="co"># misclassification error </span></span></code></pre></div>
<pre><code>## [1] 0.08</code></pre>
</div>
<div id="tree-based-models" class="section level3" number="51.3.4">
<h3>
<span class="header-section-number">51.3.4</span> 3.4 Tree-Based Models<a class="anchor" aria-label="anchor" href="#tree-based-models"><i class="fas fa-link"></i></a>
</h3>
<p>Tree-Based models, such as decision tree model can be used to visually represent the “decisions” and are widely used to generate predictions. To use tree-based models algorithm in R, we must first install the ‘rpart’ package provided by R. This package has the rpart function in it.</p>
<p>Here are some parameters explanations while we are operating ‘rpart’ to generate tree-based models:</p>
<p><code>maxdepth</code>: The maximum depth level of tree. For single split, you can just set maxdepth argument to 1.
<code>minsplit</code>: The minimum number of observations that must exist in a node in order for a split to be attempted.
<code>minbucket</code>: The minimum number of observations in any terminal node.
<code>cp</code>: Complexity parameter - setting cp to a negative amount ensures that the tree will be fully grown.
<code>method</code>: The method argument defines the algorithms. It can be one of anova, poisson, class or exp. In this case, the target variables is categorical, so you will use the method as class.</p>
<p>Success and failure modes for Tree-Based Models:</p>
<p><strong>Advanages for Tree-Based Models:</strong></p>
<ul>
<li>Does not require normalization/scaling of data.</li>
<li>Missing values in the data also do NOT affect the process of building a decision tree to any considerable extent.</li>
<li>Straightward and easy to explain to company’s stakeholders.</li>
</ul>
<p><strong>Advanages for Tree-Based Models:</strong></p>
<ul>
<li>Sensitive to small change in the data, which might generate a large change in the structure of the decision tree.</li>
<li>High time-complexity.</li>
<li>DInadequate for applying regression and predicting continuous values.</li>
</ul>
<p>Reference:</p>
<p><a href="https://blog.dataiku.com/tree-based-models-how-they-work-in-plain-english" class="uri">https://blog.dataiku.com/tree-based-models-how-they-work-in-plain-english</a>
<a href="https://www.pluralsight.com/guides/explore-r-libraries:-rpart" class="uri">https://www.pluralsight.com/guides/explore-r-libraries:-rpart</a></p>
<div class="sourceCode" id="cb833"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/warnings.html">warnings</a></span><span class="op">(</span><span class="st">'off'</span><span class="op">)</span></span>
<span><span class="co"># install.packages('rpart')       #Install class package</span></span>
<span><span class="co"># library(rpart)                    # Load class package</span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  ClaimID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">7</span>,</span>
<span>  RearEnd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">TRUE</span>, <span class="cn">TRUE</span>, <span class="cn">FALSE</span>, <span class="cn">FALSE</span>, <span class="cn">FALSE</span>, <span class="cn">FALSE</span>, <span class="cn">FALSE</span><span class="op">)</span>,</span>
<span>  Whiplash <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">TRUE</span>, <span class="cn">TRUE</span>, <span class="cn">TRUE</span>, <span class="cn">TRUE</span>, <span class="cn">TRUE</span>, <span class="cn">FALSE</span>, <span class="cn">FALSE</span><span class="op">)</span>,</span>
<span>  Fraud <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">TRUE</span>, <span class="cn">TRUE</span>, <span class="cn">TRUE</span>, <span class="cn">FALSE</span>, <span class="cn">FALSE</span>, <span class="cn">FALSE</span>, <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">mytree</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/rpart/man/rpart.html">rpart</a></span><span class="op">(</span></span>
<span>  <span class="va">Fraud</span> <span class="op">~</span> <span class="va">RearEnd</span> <span class="op">+</span> <span class="va">Whiplash</span>,   <span class="co"># y ~ feature1 + feature2 + feature3 + ...</span></span>
<span>  data <span class="op">=</span> <span class="va">train</span>, </span>
<span>  method <span class="op">=</span> <span class="st">"class"</span>,            </span>
<span>  maxdepth <span class="op">=</span> <span class="fl">1</span>, </span>
<span>  minsplit <span class="op">=</span> <span class="fl">2</span>, </span>
<span>  minbucket <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span></span>
<span><span class="va">predict_Fraud</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mytree</span>, data<span class="op">=</span><span class="va">train</span>, type <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">train</span><span class="op">$</span><span class="va">Fraud</span>, <span class="va">predict_Fraud</span><span class="op">)</span></span></code></pre></div>
<pre><code>##        predict_Fraud
##         FALSE TRUE
##   FALSE     4    0
##   TRUE      1    2</code></pre>
</div>
</div>
<div id="unsupervised-learning" class="section level2" number="51.4">
<h2>
<span class="header-section-number">51.4</span> 4. Unsupervised Learning<a class="anchor" aria-label="anchor" href="#unsupervised-learning"><i class="fas fa-link"></i></a>
</h2>
<div id="k-means" class="section level3" number="51.4.1">
<h3>
<span class="header-section-number">51.4.1</span> 4.1 K-means<a class="anchor" aria-label="anchor" href="#k-means"><i class="fas fa-link"></i></a>
</h3>
<p>K-means clustering finds k (a chosen parameter) center points that produce clusters minimizing the within-cluster sum of squares.</p>
<p>To implement K-means in R, use function ‘kmeans()’ in package ‘stats’.</p>
<p><strong>K-means Advantages: </strong><br>
1. Intuitive cluster structure<br>
2. easy to compute<br>
3. Can increase algorithm flexible with extension to other measures, such as Eucliean distance</p>
<p><strong>K-means Disadvantages: </strong><br>
1. Hard to interpret<br>
2. Problematic with high-dimensional data</p>
<p>Reference:
<a href="https://www.guru99.com/r-k-means-clustering.html" class="uri">https://www.guru99.com/r-k-means-clustering.html</a></p>
<div class="sourceCode" id="cb835"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>age <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">18</span>, <span class="fl">21</span>, <span class="fl">22</span>, <span class="fl">24</span>, <span class="fl">26</span>, <span class="fl">26</span>, <span class="fl">27</span>, <span class="fl">30</span>, <span class="fl">31</span>, <span class="fl">35</span>, <span class="fl">39</span>, <span class="fl">40</span>, <span class="fl">41</span>, <span class="fl">42</span>, <span class="fl">44</span>, <span class="fl">46</span>, <span class="fl">47</span>, <span class="fl">48</span>, <span class="fl">49</span>, <span class="fl">54</span><span class="op">)</span>,</span>
<span>    spend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">11</span>, <span class="fl">22</span>, <span class="fl">15</span>, <span class="fl">12</span>, <span class="fl">13</span>, <span class="fl">14</span>, <span class="fl">33</span>, <span class="fl">39</span>, <span class="fl">37</span>, <span class="fl">44</span>, <span class="fl">27</span>, <span class="fl">29</span>, <span class="fl">20</span>, <span class="fl">28</span>, <span class="fl">21</span>, <span class="fl">30</span>, <span class="fl">31</span>, <span class="fl">23</span>, <span class="fl">24</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">kmeans_out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/kmeans.html">kmeans</a></span><span class="op">(</span><span class="va">df</span>, centers<span class="op">=</span><span class="fl">3</span>, nstart<span class="op">=</span><span class="fl">5</span><span class="op">)</span> </span>
<span><span class="co"># centers: number of centers, i.e. k, nstart: number of runs</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">kmeans_out</span><span class="op">)</span><span class="op">)</span> </span></code></pre></div>
<pre><code>## List of 9
##  $ cluster     : int [1:20] 2 2 2 2 2 2 2 3 3 3 ...
##  $ centers     : num [1:3, 1:2] 45.7 23.4 33.8 25.9 13.9 ...
##   ..- attr(*, "dimnames")=List of 2
##   .. ..$ : chr [1:3] "1" "2" "3"
##   .. ..$ : chr [1:2] "age" "spend"
##  $ totss       : num 4086
##  $ withinss    : num [1:3] 287 159 114
##  $ tot.withinss: num 559
##  $ betweenss   : num 3527
##  $ size        : int [1:3] 9 7 4
##  $ iter        : int 1
##  $ ifault      : int 0
##  - attr(*, "class")= chr "kmeans"
## NULL</code></pre>
<div class="sourceCode" id="cb837"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># choose parameter k</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">'one option to choose k:'</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] "one option to choose k:"</code></pre>
<div class="sourceCode" id="cb839"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># library('NbClust')</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/NbClust/man/NbClust.html">NbClust</a></span><span class="op">(</span><span class="va">df</span>, method<span class="op">=</span><span class="st">'kmeans'</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="machine_learning_in_r_files/figure-html/unnamed-chunk-7-1.png" width="80%" style="display: block; margin: auto;"></div>
<pre><code>## *** : The Hubert index is a graphical method of determining the number of clusters.
##                 In the plot of Hubert index, we seek a significant knee that corresponds to a 
##                 significant increase of the value of the measure i.e the significant peak in Hubert
##                 index second differences plot. 
## </code></pre>
<div class="inline-figure"><img src="machine_learning_in_r_files/figure-html/unnamed-chunk-7-2.png" width="80%" style="display: block; margin: auto;"></div>
<pre><code>## *** : The D index is a graphical method of determining the number of clusters. 
##                 In the plot of D index, we seek a significant knee (the significant peak in Dindex
##                 second differences plot) that corresponds to a significant increase of the value of
##                 the measure. 
##  
## ******************************************************************* 
## * Among all indices:                                                
## * 5 proposed 2 as the best number of clusters 
## * 8 proposed 3 as the best number of clusters 
## * 2 proposed 6 as the best number of clusters 
## * 1 proposed 9 as the best number of clusters 
## * 1 proposed 13 as the best number of clusters 
## * 3 proposed 14 as the best number of clusters 
## * 3 proposed 15 as the best number of clusters 
## 
##                    ***** Conclusion *****                            
##  
## * According to the majority rule, the best number of clusters is  3 
##  
##  
## *******************************************************************</code></pre>
<pre><code>## $All.index
##        KL      CH Hartigan    CCC    Scott   Marriot       TrCovW    TraceW
## 2  1.2431 35.4703  26.2896 8.6322  96.5441 1360896.9 1105591.3021 1375.3407
## 3  4.1320 53.6282   2.6252 7.2987 126.4970  684840.9   55337.6534  558.9603
## 4  1.8704 39.6689   2.6613 5.4159 131.7934  934235.7   55238.6391  484.1889
## 5  0.3264 33.1553   7.6439 4.3631 138.4340 1047319.3   30612.3893  415.1389
## 6  1.7737 38.7983   0.2593 4.5180 171.1657  293548.5    4564.6250  275.0000
## 7  1.8848 30.6186   2.9304 4.9900 171.7046  388931.4    4280.1250  270.0000
## 8  0.3588 30.0730   4.9036 4.5055 169.2846  573330.7    3215.1250  220.3333
## 9  4.1470 34.5395   0.5218 4.6757 187.5561  291038.1     858.2951  156.4167
## 10 1.4384 29.2873   0.5785 3.4977 193.2832  269837.5     499.8472  149.3333
## 11 0.5166 25.1472   0.1403 2.3311 197.9108  259061.0     305.8889  141.1667
## 12 0.1263 20.6491  11.1175 0.9160 198.3678  301338.0     305.1250  139.0000
## 13 6.0055 40.3892   2.4324 3.2335 221.4263  111652.7     333.0139   58.1667
## 14 4.2570 43.2212   0.0703 2.8244 234.0614   68845.0     127.1806   43.1667
## 15 1.3375 33.8411   0.1200 0.9070 234.6244   76837.5     120.7222   42.6667
##     Friedman    Rubin Cindex     DB Silhouette     Duda Pseudot2   Beale
## 2    80.9009  29.7781 0.3921 0.5914     0.5914   1.7158  -3.7545 -0.3476
## 3   149.6540  73.2700 0.4819 0.5632     0.6190   0.5285   4.4613  0.7436
## 4   170.8682  84.5848 0.4732 0.7032     0.5108   1.0340  -0.3616 -0.0288
## 5   197.4042  98.6537 0.4607 0.4901     0.5842   0.5115   6.6846  0.8356
## 6   602.4613 148.9273 0.3345 0.6424     0.5027   0.7643   0.9251  0.2056
## 7   609.6454 151.6852 0.3406 0.5304     0.5304   0.9958   0.0167  0.0031
## 8   520.7992 185.8775 0.3223 0.4990     0.5055   0.1986  12.1071  2.6905
## 9   861.1014 261.8327 0.2736 0.4105     0.5578   0.2735   5.3125  1.7708
## 10 1096.0498 274.2522 0.2950 0.3885     0.5726   0.3281   4.0952  1.0238
## 11 1330.3576 290.1181 0.3097 0.3804     0.5750  32.0625  -0.9688 -0.4844
## 12 1337.2837 294.6403 0.3546 0.3614     0.5899   0.3979   3.0258  1.0086
## 13 1665.2066 704.0974 0.5282 0.3129     0.6254  35.1154  -0.9715  0.0000
## 14 2596.5348 948.7645 0.4816 0.2639     0.6786 365.0000   0.0000  0.0000
## 15 2630.5486 959.8828 0.5618 0.2361     0.7363 229.0000   0.0000  0.0000
##    Ratkowsky     Ball Ptbiserial    Frey McClain   Dunn Hubert SDindex Dindex
## 2     0.5739 687.6703     0.7746  0.5608  0.4002 0.4953  3e-04  0.7367 7.0787
## 3     0.5359 186.3201     0.8160  9.9687  0.6255 0.6984  4e-04  0.4144 4.8537
## 4     0.4690 121.0472     0.7282  2.2944  0.8296 0.3492  4e-04  0.4912 4.3689
## 5     0.4238  83.0278     0.7004  0.9228  0.9179 0.3492  4e-04  0.4373 3.8278
## 6     0.3946  45.8333     0.5808 -1.3492  1.4477 0.3518  4e-04  0.4092 3.0061
## 7     0.3656  38.5714     0.5654  2.1054  1.5392 0.2225  4e-04  0.7252 2.8480
## 8     0.3437  27.5417     0.5014  0.4345  1.9911 0.2225  4e-04  0.7344 2.4716
## 9     0.3269  17.3796     0.4701 -1.0099  2.2176 0.2225  4e-04  0.7077 2.0351
## 10    0.3104  14.9333     0.4167 -0.9334  2.9156 0.1990  4e-04  0.7371 1.8780
## 11    0.2962  12.8333     0.3802 -0.3310  3.5696 0.1990  4e-04  0.7401 1.7159
## 12    0.2837  11.5833     0.3323  0.0779  4.8127 0.0995  4e-04  1.2537 1.6364
## 13    0.2754   4.4744     0.3214  0.2922  4.5949 0.2209  4e-04  1.2893 1.1840
## 14    0.2658   3.0833     0.3050 -0.2257  4.9542 0.2209  5e-04  1.2708 0.9032
## 15    0.2568   2.8444     0.2734 -0.1804  6.5449 0.1562  5e-04  2.3150 0.8532
##      SDbw
## 2  0.2844
## 3  0.1359
## 4  0.1000
## 5  0.0645
## 6  0.0617
## 7  0.0507
## 8  0.0574
## 9  0.0272
## 10 0.0238
## 11 0.0204
## 12 0.0184
## 13 0.0104
## 14 0.0058
## 15 0.0053
## 
## $All.CriticalValues
##    CritValue_Duda CritValue_PseudoT2 Fvalue_Beale
## 2         -0.2510           -44.8510       1.0000
## 3         -0.2510           -24.9172       0.5000
## 4         -0.1409           -89.0698       1.0000
## 5         -0.1409           -56.6808       0.4541
## 6         -0.5522            -8.4329       0.8223
## 7         -0.4219           -13.4803       0.9969
## 8         -0.5522            -8.4329       0.1818
## 9         -0.5522            -5.6219       0.2813
## 10        -0.7431            -4.6915       0.4941
## 11        -0.7431            -2.3458       1.0000
## 12        -0.5522            -5.6219       0.4419
## 13        -1.0633            -1.9405          NaN
## 14        -1.0633             0.0000          NaN
## 15        -1.0633             0.0000          NaN
## 
## $Best.nc
##                      KL      CH Hartigan    CCC   Scott  Marriot  TrCovW
## Number_clusters 13.0000  3.0000   3.0000 2.0000  6.0000      3.0       3
## Value_Index      6.0055 53.6282  23.6644 8.6322 32.7318 925450.8 1050254
##                   TraceW Friedman     Rubin Cindex      DB Silhouette   Duda
## Number_clusters   3.0000  14.0000   14.0000 9.0000 15.0000    15.0000 2.0000
## Value_Index     741.6089 931.3281 -233.5487 0.2736  0.2361     0.7363 1.7158
##                 PseudoT2   Beale Ratkowsky     Ball PtBiserial Frey McClain
## Number_clusters       14  2.0000    2.0000   3.0000      3.000    1  2.0000
## Value_Index            0 -0.3476    0.5739 501.3502      0.816   NA  0.4002
##                   Dunn Hubert SDindex Dindex    SDbw
## Number_clusters 3.0000      0  6.0000      0 15.0000
## Value_Index     0.6984      0  0.4092      0  0.0053
## 
## $Best.partition
##  [1] 3 3 3 3 3 3 3 1 1 1 1 2 2 2 2 2 2 2 2 2</code></pre>
</div>
<div id="principle-component-analysis" class="section level3" number="51.4.2">
<h3>
<span class="header-section-number">51.4.2</span> 4.2 Principle Component Analysis<a class="anchor" aria-label="anchor" href="#principle-component-analysis"><i class="fas fa-link"></i></a>
</h3>
<p>The main feature of unsupervised learning algorithms, when compared to classification and regression methods, is that input data are unlabeled (i.e. no labels or classes given) and that the algorithm learns the structure of the data without any assistance. This creates two main differences. First, it allows us to process large amounts of data because the data does not need to be manually labeled. Second, it is difficult to evaluate the quality of an unsupervised algorithm due to the absence of an explicit goodness metric as used in supervised learning.</p>
<p>One of the most common tasks in unsupervised learning is dimensionality reduction. On one hand, dimensionality reduction may help with data visualization. On the other hand, it may help deal with the multicollinearity of our data and prepare the data for a supervised learning method (e.g. decision trees).</p>
<p>To use PCA models algorithm in R, we can use “princomp” provided by R. This package has the “PCA” function in it.</p>
<p>Success and failure modes for Principle Component Analysis (PCA):</p>
<p><strong>Advanages for PCA:</strong></p>
<ul>
<li>Removes correlated features</li>
<li>Improves algorithm performance by reducing overfitting</li>
<li>Improves visualization by transforming high dimensional data to low dimensional data</li>
</ul>
<p><strong>Advanages for PCA:</strong></p>
<ul>
<li>May miss some information as compared to the original list of features.</li>
<li>Independent principal components are not as readable and interpretable as original features sometimes.</li>
</ul>
<p>Reference:</p>
<p><a href="https://www.i2tutorials.com/what-are-the-pros-and-cons-of-the-pca/" class="uri">https://www.i2tutorials.com/what-are-the-pros-and-cons-of-the-pca/</a>
<a href="https://www.datacamp.com/tutorial/pca-analysis-r" class="uri">https://www.datacamp.com/tutorial/pca-analysis-r</a>
<a href="https://www.r-bloggers.com/2021/05/principal-component-analysis-pca-in-r/" class="uri">https://www.r-bloggers.com/2021/05/principal-component-analysis-pca-in-r/</a></p>
<div class="sourceCode" id="cb843"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#warnings('off')</span></span>
<span><span class="co">#install.packages('usethis')</span></span>
<span><span class="co">#library(usethis)</span></span>
<span><span class="co"># install.packages('devtools')</span></span>
<span><span class="co">#library(devtools)</span></span>
<span><span class="co"># install_github("vqv/ggbiplot")</span></span>
<span><span class="co"># library(ggbiplot)</span></span>
<span><span class="va">iris1</span><span class="op">&lt;-</span><span class="va">iris</span><span class="op">[</span>,<span class="op">-</span><span class="fl">5</span><span class="op">]</span></span>
<span><span class="va">basePCA</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/princomp.html">princomp</a></span><span class="op">(</span><span class="va">iris1</span><span class="op">)</span>     <span class="co"># Default: center = TRUE, scale. = TRUE</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">basePCA</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Importance of components:
##                           Comp.1     Comp.2     Comp.3      Comp.4
## Standard deviation     2.0494032 0.49097143 0.27872586 0.153870700
## Proportion of Variance 0.9246187 0.05306648 0.01710261 0.005212184
## Cumulative Proportion  0.9246187 0.97768521 0.99478782 1.000000000</code></pre>
<div class="sourceCode" id="cb845"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># PCA Visualization</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/ggbiplot/man/ggbiplot.html">ggbiplot</a></span><span class="op">(</span><span class="va">basePCA</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="machine_learning_in_r_files/figure-html/unnamed-chunk-8-1.png" width="80%" style="display: block; margin: auto;"></div>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="introduction-to-common-sampling-techniques-in-r.html"><span class="header-section-number">50</span> Introduction to common sampling techniques in r</a></div>
<div class="next"><a href="what-you-see-is-what-you-understand-learning-data-science-visually.html"><span class="header-section-number">52</span> What you see is what you understand: learning data science visually</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#machine-learning-in-r"><span class="header-section-number">51</span> Machine Learning in R</a></li>
<li><a class="nav-link" href="#contribution"><span class="header-section-number">51.1</span> 1. Contribution</a></li>
<li><a class="nav-link" href="#evaluation-3"><span class="header-section-number">51.2</span> 2. Evaluation</a></li>
<li>
<a class="nav-link" href="#supervised-learning-in-r"><span class="header-section-number">51.3</span> 3. Supervised Learning in R</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#linear-regression"><span class="header-section-number">51.3.1</span> 3.1 Linear Regression</a></li>
<li><a class="nav-link" href="#logistic-regression"><span class="header-section-number">51.3.2</span> 3.2 Logistic Regression</a></li>
<li><a class="nav-link" href="#k-nearest-neighboors"><span class="header-section-number">51.3.3</span> 3.3 k-Nearest Neighboors</a></li>
<li><a class="nav-link" href="#tree-based-models"><span class="header-section-number">51.3.4</span> 3.4 Tree-Based Models</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#unsupervised-learning"><span class="header-section-number">51.4</span> 4. Unsupervised Learning</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#k-means"><span class="header-section-number">51.4.1</span> 4.1 K-means</a></li>
<li><a class="nav-link" href="#principle-component-analysis"><span class="header-section-number">51.4.2</span> 4.2 Principle Component Analysis</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/jtr13/cc22tt/blob/main/machine_learning_in_r.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/jtr13/cc22tt/edit/main/machine_learning_in_r.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Community Contributions for EDAV Fall 2022 Tues/Thurs</strong>" was written by . It was last built on 2022-12-10.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
