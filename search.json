[{"path":"index.html","id":"welcome","chapter":"1 Welcome!","heading":"1 Welcome!","text":"Let’s add content welcome page.Submit pull request .construction","code":""},{"path":"community-contribution.html","id":"community-contribution","chapter":"2 Community Contribution","heading":"2 Community Contribution","text":"fairly open-ended assignment provides opportunity receive credit contributing collective learning class, perhaps beyond. reflect minimum 3 hours work. complete assignment must submit short description contribution. appropriate, attach relevant files.many ways can contribute:organize lead workshop particular topic (date may assignment due date need schedule )help students find final project partnersgive well-rehearsed 5 minute lightning talk class datavis topic (theory tool) (email set date – may assignment due date need schedule )create video tutorial (length)create cheatsheet resourcewrite tutorial tool ’s well documentedbuild viz product (ex. htmlwidget RStudio add-) class use[idea](Note: translations allowed)may draw expand existing resources. , critical cite sources.","code":""},{"path":"community-contribution.html","id":"important-logistics","chapter":"2 Community Contribution","heading":"2.1 IMPORTANT LOGISTICS","text":"","code":""},{"path":"community-contribution.html","id":"groups","chapter":"2 Community Contribution","heading":"2.1.1 Groups","text":"may work partner choosing. work alone, need join group 1, simply submit work CourseWorks solo assignment.work partner, add group CC page People tab. Ed Discussion can used find partners similar interests.","code":""},{"path":"community-contribution.html","id":"what-to-submit","chapter":"2 Community Contribution","heading":"2.1.2 What to submit","text":"cases something tangible upload, tutorial, cheatsheet, etc. Alternatively may submit link material online (YouTube video, etc.) ’s nothing tangible include longer description (see 2.).cases something tangible upload, tutorial, cheatsheet, etc. Alternatively may submit link material online (YouTube video, etc.) ’s nothing tangible include longer description (see 2.).explanation motivation project, need addresses, evaluation project including learned / might differently next time. (1/2 page)explanation motivation project, need addresses, evaluation project including learned / might differently next time. (1/2 page)","code":""},{"path":"community-contribution.html","id":"submitting-your-assignment","chapter":"2 Community Contribution","heading":"2.1.3 Submitting your assignment","text":"must submit assignment twice: CourseWorks (can graded) class, details follow.CourseWorks submission (assignment): submit work .Rmd rendered .pdf .html file, just problem sets. work lend format, write assignment text box .CourseWorks submission (assignment): submit work .Rmd rendered .pdf .html file, just problem sets. work lend format, write assignment text box .Class (GitHub) submission: detail provided separate assignment.Class (GitHub) submission: detail provided separate assignment.","code":""},{"path":"community-contribution.html","id":"grading","chapter":"2 Community Contribution","heading":"2.1.4 Grading","text":"graded quality work, originality, effort invested. sources used must cited.","code":""},{"path":"github-submission-instructions.html","id":"github-submission-instructions","chapter":"3 GitHub submission instructions","heading":"3 GitHub submission instructions","text":"chapter gives information need upload community contribution. Please read entire document carefully making submission. particular note fact bookdown requires different .Rmd format ’re used , must make changes beginning file described submitting.","code":""},{"path":"github-submission-instructions.html","id":"background","chapter":"3 GitHub submission instructions","heading":"3.1 Background","text":"web site makes use bookdown package render collection .Rmd files nicely formatted online book chapters subchapters. job submit slightly modified version community contribution .Rmd file GitHub repository source files web site stored. backend, admins divide chapters book sections order .community contribution different format, create short .Rmd file explains , includes links relevant files, slides, etc. can post GitHub repo (another online site.)","code":""},{"path":"github-submission-instructions.html","id":"preparing-your-.rmd-file","chapter":"3 GitHub submission instructions","heading":"3.2 Preparing your .Rmd file","text":"submit ONE Rmd file.completing modifications, .Rmd look like sample .Rmd.Create concise, descriptive name project. instance, name base_r_ggplot_graph something similar work contrasting/working base R graphics ggplot2 graphics. Check .Rmd filenames file make sure name isn’t already taken. project name words joined underscores, white space. Use .Rmd .rmd. addition, letters must lowercase. Create copy .Rmd file new name.Create concise, descriptive name project. instance, name base_r_ggplot_graph something similar work contrasting/working base R graphics ggplot2 graphics. Check .Rmd filenames file make sure name isn’t already taken. project name words joined underscores, white space. Use .Rmd .rmd. addition, letters must lowercase. Create copy .Rmd file new name.Completely delete YAML header (section top .Rmd includes name, title, date, output, etc.) including --- line.Completely delete YAML header (section top .Rmd includes name, title, date, output, etc.) including --- line.Choose short, descriptive, human readable title project title show table contents – look examples panel left. Capitalize first letter (“sentence case”). first line document, enter single hashtag, followed single whitespace, title. important follow format bookdown renders title header. use single # headers anywhere else document.Choose short, descriptive, human readable title project title show table contents – look examples panel left. Capitalize first letter (“sentence case”). first line document, enter single hashtag, followed single whitespace, title. important follow format bookdown renders title header. use single # headers anywhere else document.second line blank, followed name(s):\n# Base R vs. ggplot2\n\nAaron Burr Alexander Hamilton\n\ncontent starts . second line blank, followed name(s):project requires data, please use built-dataset read directly URL, :\ndf <- readr::read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")  absolutely must include data file, please use small one, many reasons desirable keep repository size small possible.project requires data, please use built-dataset read directly URL, :df <- readr::read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")  absolutely must include data file, please use small one, many reasons desirable keep repository size small possible.included setup chunk .Rmd file, please remember remove label setup chunk, .e., use:\n{r, include=FALSE}\ninstead :\n{r setup, include=FALSE}included setup chunk .Rmd file, please remember remove label setup chunk, .e., use:instead :project requires libraries installed included document, please adhere following conventions. evaluate install.packages() statements document. Consumers .Rmd file won’t want packages get installed knit document. Include library() statements top .Rmd file, title, name, setup, content. chapter requires installation package source (GitHub installation), please add comment identifying . Please mention well PR. example library() section install statements won’t evaluated:\n\n# remotes::install_github(\"twitter/AnomalyDetection\")\nlibrary(\"AnomalyDetection\") # must installed sourceIf project requires libraries installed included document, please adhere following conventions. evaluate install.packages() statements document. Consumers .Rmd file won’t want packages get installed knit document. Include library() statements top .Rmd file, title, name, setup, content. chapter requires installation package source (GitHub installation), please add comment identifying . Please mention well PR. example library() section install statements won’t evaluated:developed .Rmd file moving library() statements rest file content, highly recommended knit review document . may change namespace available section code development, causing function work exhibit unexpected behavior.file contain getwd() / setwd() calls (never use scripts anyway!) write statements.Want get fancy? See optional tweaks section .","code":"# Base R vs. ggplot2\n\nAaron Burr and Alexander Hamilton\n\nYour content starts here. {r, include=FALSE}{r setup, include=FALSE}\n# remotes::install_github(\"twitter/AnomalyDetection\")\nlibrary(\"AnomalyDetection\") # must be installed from source"},{"path":"github-submission-instructions.html","id":"submission-steps","chapter":"3 GitHub submission instructions","heading":"3.3 Submission steps","text":"submit work, following “Workflow #4” – submitting pull request someone else’s repository write access. Instructions available lecture slides topic well tutorial. repeated abbreviated form, specific instructions naming conventions, content information, important details.Fork cc22tt repo (repo) GitHub account.Fork cc22tt repo (repo) GitHub account.Clone/download forked repo local computer.Clone/download forked repo local computer.Create new branch name project name, case sample_project. skip step. merge PR doesn’t come branch. already forgot , check tutorial fix .Create new branch name project name, case sample_project. skip step. merge PR doesn’t come branch. already forgot , check tutorial fix .Copy modified .Rmd file name root directory branch. example, sample_project.Rmd.Copy modified .Rmd file name root directory branch. example, sample_project.Rmd.include .html file. (order bookdown package work, .Rmd files rendered behind scenes.)include .html file. (order bookdown package work, .Rmd files rendered behind scenes.)[OPTIONAL] resources (images) included project, create folder resources/. example, resources/sample_project/. Put resources files . sure change links .Rmd include resources/.../, example:\n![Test Photo](resources/sample_project/pumpkins.jpg)[OPTIONAL] resources (images) included project, create folder resources/. example, resources/sample_project/. Put resources files . sure change links .Rmd include resources/.../, example:![Test Photo](resources/sample_project/pumpkins.jpg)ready submit project, push branch remote repo. Follow tutorial create pull request.ready submit project, push branch remote repo. Follow tutorial create pull request.point back forth begin team managing pull requests. asked make changes, simply make changes local branch, save, commit, push GitHub. new commits added pull request; need , , create new pull request. (, based circumstances, make sense close pull request start new one, tell .)point back forth begin team managing pull requests. asked make changes, simply make changes local branch, save, commit, push GitHub. new commits added pull request; need , , create new pull request. (, based circumstances, make sense close pull request start new one, tell .)pull request merged, ’s fine delete local clone (folder) well forked repository GitHub account.pull request merged, ’s fine delete local clone (folder) well forked repository GitHub account.","code":""},{"path":"github-submission-instructions.html","id":"optional-tweaks","chapter":"3 GitHub submission instructions","heading":"3.4 Optional tweaks","text":"prefer links chapter open new tabs, add {target=\"_blank\"} link, :\n[edav.info](edav.info){target=\"_blank\"}prefer links chapter open new tabs, add {target=\"_blank\"} link, :[edav.info](edav.info){target=\"_blank\"}Note headers (##, ###, etc.) converted numbered headings : ## –> 3.1 ### –> 3.1.1  headings appear chapter subheadings sub-subheadings navigation panel left. Think logical structure users navigate chapter. recommend using ## ### headings since “sub-sub-subheadings” 4.1.3.4 generally unnecessary look messy.Note headers (##, ###, etc.) converted numbered headings : ## –> 3.1 ### –> 3.1.1  headings appear chapter subheadings sub-subheadings navigation panel left. Think logical structure users navigate chapter. recommend using ## ### headings since “sub-sub-subheadings” 4.1.3.4 generally unnecessary look messy.Unfortunately, ’s simple way preview chapter ’s actually merged project. (bookdown preview_chapter() option works entire book rendered least become complex require packages project grows.) really want preview , fork clone minimal bookdown repo, add .Rmd file, click “Build book” button Build tab (next Git), open .html files _book folder web browser see rendered book.  ’re interested bookdown options, see official reference book.  useful tweaks share? Submit issue PR.Unfortunately, ’s simple way preview chapter ’s actually merged project. (bookdown preview_chapter() option works entire book rendered least become complex require packages project grows.) really want preview , fork clone minimal bookdown repo, add .Rmd file, click “Build book” button Build tab (next Git), open .html files _book folder web browser see rendered book.  ’re interested bookdown options, see official reference book.  useful tweaks share? Submit issue PR.","code":""},{"path":"github-submission-instructions.html","id":"faq","chapter":"3 GitHub submission instructions","heading":"3.5 FAQ","text":"","code":""},{"path":"github-submission-instructions.html","id":"what-should-i-expect-after-creating-a-pull-request","chapter":"3 GitHub submission instructions","heading":"3.5.1 What should I expect after creating a pull request?","text":"Within week create pull request, apply label assign classmate “PR merger” review files submit see meet requirements.Within week create pull request, apply label assign classmate “PR merger” review files submit see meet requirements.take time can process pull requests, long see pull request repo, don’t worry.take time can process pull requests, long see pull request repo, don’t worry.PR merger contacts regarding pull request, usually means files fail meet requirements. explain wrong, please fix soon possible.PR merger contacts regarding pull request, usually means files fail meet requirements. explain wrong, please fix soon possible.","code":""},{"path":"github-submission-instructions.html","id":"what-if-i-catch-mistakes-before-my-pull-request-is-merged","chapter":"3 GitHub submission instructions","heading":"3.5.2 What if I catch mistakes before my pull request is merged?","text":"Just make changes branch, commit push GitHub. automatically added pull request.","code":""},{"path":"github-submission-instructions.html","id":"what-if-i-catch-mistakes-after-my-pull-request-is-merged","chapter":"3 GitHub submission instructions","heading":"3.5.3 What if I catch mistakes after my pull request is merged?","text":"may submit additional pull requests fix material site. edits small, fixing typos, easiest make edits directly GitHub, following instructions. merge first pull requests edits, please patient.","code":""},{"path":"github-submission-instructions.html","id":"other-questions","chapter":"3 GitHub submission instructions","heading":"3.5.4 Other questions","text":"additional questions, please ask Discussions section respond.Thank contributions!","code":""},{"path":"sample-project.html","id":"sample-project","chapter":"4 Sample project","heading":"4 Sample project","text":"Joe Biden Donald TrumpThis chapter gives sample layout Rmd file.Test Photo","code":""},{"path":"r-window-functions-cheatsheet.html","id":"r-window-functions-cheatsheet","chapter":"6 R window functions cheatsheet","heading":"6 R window functions cheatsheet","text":"Gokul Sunilkumar Pooja SrinivasanWhat window function?window function performs calculation across set table rows somehow related current row. Although functionalities might sound similar aggregate functions, window functions cause rows become grouped single output row like non-window aggregate calls . Instead, rows retain separate identities. Behind scenes, window function able access just current row query result.Although usage window functions common database systems related applications, single source lookup help ease developers’ work programming. Hence, come cheatsheet .Check cheatsheet : https://github.com/gokul-sunilkumar/RWindowFunctions/blob/main/RWindowFunctionsCheatSheet.pdf","code":""},{"path":"rmd-chunk-option-cheat-sheet.html","id":"rmd-chunk-option-cheat-sheet","chapter":"7 Rmd chunk option cheat sheet","heading":"7 Rmd chunk option cheat sheet","text":"Yunchen JiangMotivation ContributionAs graduate student undergraduate degree actuarial mathematics, course almost first exposure Rstudio. received Pset, first thing confused code chunk r markdown. project, contribute making condensed cheat sheet commonly used chunk options refine understanding rmd files simultaneously help r beginners similar situation .Cheat sheetChunk options written chunk headers form tag=value like :\n{r -chunk, echo=FALSE, fig.height=4, dev=‘jpeg’}\n…special chunk option chunk label (e.g., -chunk example). chunk label need tag. prefer form tag=value, also use chunk option label explicitly:\n{r, label=‘-chunk’, echo=FALSE, fig.height=4, dev=‘jpeg’}\n…can also write chunk options body code chunk #| like :\n{r}\n#| -chunk, echo = FALSE,\n#| fig.height=4, dev=‘jpeg’\n…syntax, chunk options must written continuous lines beginning chunk body. can break options onto many lines wish lines must start special comment prefix #|can also use YAML syntax write options inside chunk form tag: value. Normally provide one option per line like :\n{r}\n#| echo: false\n#| fig.width: 4\n#| dev: ‘jpeg’\n…chunk label chunk assumed unique within document. especially important cache plot filenames, filenames based chunk labels.list commonly used chunk options knitr documented format “option: (default value; type value)“.Code evaluation:eval: (TRUE; logical numeric) Whether evaluate code chunk. can also numeric vector choose R expression(s) evaluate.\ne.g., eval = c(1, 3, 4) evaluate first, third, fourth expressions, eval = -(4:5) evaluate expressions except fourth fifth.Text output:echo: (TRUE; logical numeric) Whether display source code output document. Besides TRUE/FALSE, shows/hides source code, can also use numeric vector choose R expression(s) echo chunk.\ne.g., echo = 2:3 means echo 2nd 3rd expressions, echo = -4 means exclude 4th expression.results: (‘markup’) Mark text output appropriate environments depending output format. example, R Markdown, text output character string “[1] 1 2 3”, actual output knitr produces :case, results=‘markup’ means put text output fenced code blocks.warning: (TRUE; logical) Whether preserve warnings (produced warning()) output. FALSE, warnings printed console instead output document:\n{r}\nwithCallingHandlers(\nexpr = .numeric(c(“1”, “”)),\nwarning = function(w) warn <<- paste(“** warning:”, w$message, \"**\")\n)\nWarning: NAs introduced coercion[1] 1 NA{r, warning = false}\nwithCallingHandlers(\nexpr = .numeric(c(“1”, “”)),\nwarning = function(w) warn <<- paste(“** warning:”, w$message, \"**\")\n)\n[1] 1 NAIt can also take numeric values indices select subset warnings include output. Note values reference indices warnings (e.g., 3 means “third warning thrown chunk”) indices expressions allowed emit warnings.error: (True; logical) Whether preserve errors (stop()). default, errors code chunks Rmd document halt R. want show errors without stopping R, may use chunk option error = TRUE:\n{r,error = TRUE}\n1 + “”\nsee error message output document compile Rmd document: Error 1 + “”: non-numeric argument binary operator. R Markdown, error = FALSE default, means R stop error running code chunks.include: (TRUE; logical) Whether include chunk output output document. FALSE, nothing written output document, code still evaluated plot files generated plots chunk, can manually insert figures later.Code decoration:comment: (‘##’; character) prefix added line text output. default, text output commented ##, readers want copy run source code output document, can select copy everything chunk, since text output masked comments (ignored running copied text). Set comment = ’’ remove default ##.prompt: (FALSE; logical) Whether add prompt characters R code. TRUE, knitr add > start line code displayed final document. Note adding prompts can make difficult readers copy R code output, prompt = FALSE may better choice.highlight: (TRUE) Whether syntax highlight source code.Cache:cache: (FALSE; logical) Whether cache code chunk. caching turned via chunk option cache = TRUE, knitr write R objects generated code chunk cache database, can reloaded next time. evaluating code chunks second time, cached chunks skipped (unless modified), objects created chunks loaded previously saved databases (.rdb .rdx files), files saved chunk evaluated first time, cached files found (e.g., may removed hand).cache.path: (‘cache/’; character) prefix used generate paths cache files. R Markdown, default value based input filename, e.g., cache paths chunk label FOO file INPUT.Rmd form INPUT_cache/FOO_..cache.lazy: (TRUE; logical) Whether lazyLoad() directly load() objects. large objects, lazyloading may work, cache.lazy = FALSE may desirabledependson: (NULL; character numeric) character vector chunk labels specify chunks chunk depends . option applies cached chunks —sometimes objects cached chunk may depend cached chunks, chunks changed, chunk must updated accordingly. dependson numeric vector, means indices chunk labels, e.g., dependson = 1 means chunk depends first chunk document, dependson = c(-1, -2) means depends previous two chunks (negative indices stand numbers chunks chunk, note always relative current chunk).Plots:fig.width, fig.height: (7; numeric) Width height plot (inches), used graphics device.fig.ext: (NULL; character) File extension figure output. NULL, derived graphical device; see knitr:::auto_exts details.fig.asp: (NULL; numeric) aspect ratio plot, .e., ratio height/width. fig.asp specified, height plot (chunk option fig.height) calculated fig.width * fig.asp.fig.dim: (NULL; numeric) numeric vector length 2 provide fig.width fig.height, e.g., fig.dim = c(5, 7) shorthand fig.width = 5, fig.height = 7. fig.asp fig.dim provided, fig.asp ignored (warning).fig.align: (‘default’; character) Alignment figures output document. Possible values default, left, right, center. default make alignment adjustments.fig.path: (‘figure/’; character) prefix used generate figure file paths. fig.path chunk labels concatenated generate full paths. may contain directory like figure/prefix-; directory created exist.fig.show: (‘asis’; character) show/arrange plots. Possible values follows:asis: ‘hide’, knitr generate plots created chunk, include final document. ‘hold’, knitr delay displaying plots created chunk end chunk. ‘animate’, knitr combine plots created chunk animation.","code":"[1] 1 2 3"},{"path":"helpful-ggplot2-extensions-cheatsheet.html","id":"helpful-ggplot2-extensions-cheatsheet","chapter":"8 Helpful ggplot2 Extensions Cheatsheet","heading":"8 Helpful ggplot2 Extensions Cheatsheet","text":"Frank Li Liang ZhuangCurrently, total 117 ggplot2 extensions extensions add additional features ggplot2 make powerful. cheatsheet includes useful information four ggplot2 extensions: ggbump, ggradar, ggpol, treemapify.ggbump: creates varies bump charts ggplot. Bump charts good plot path nodes statistical significance.ggradar: creates radar charts. Radar charts useful data values multiple common variables widely used performance analysis.ggpol: adds additional features ggplot2 including GeomArcbar, GeomParliament, GeomCircle, GeomTshignlight, FacetShare, GeomBartext, GeomBoxjitter. details : https://erocoar.github.io/ggpol/.treemapify: creates tree maps ggplot2. useful \ndata hierarchy, country GDP company’s stock market share.extensions, use link: https://exts.ggplot2.tidyverse.org/gallery/cheatsheet available : https://github.com/leolisticierism/EDAV_Community_Contribution/blob/main/EDAV%20Community%20Contribution%20Cheat%20Sheet.pdf","code":""},{"path":"commonly-used-graph-cheatcheet.html","id":"commonly-used-graph-cheatcheet","chapter":"9 Commonly-used graph cheatcheet","heading":"9 Commonly-used graph cheatcheet","text":"Wangtao Zheng, UNI:wz2618During R coding exercises EDAV homework, realized necessity creating R code library/cheatsheet include codes used draw commonly-applied graphs data visualization. way, one need memorize code used drawing different graphs, saves time.R codes used draw commonly-used graphs thus included cheatsheet. Graphs useful data visualization projects, scatterplot, boxplot, bar plot, histogram, etc., included cheatsheet. also included coding methods various modifications graphs convenience reasons, cheatsheet can help members community different circumstances.can find cheatsheet :https://github.com/zwt950715/EDAV-Fall-2022-Community-Contribution/blob/main/%20Useful%20Cheatsheet%20For%20Data%20Visualization.pdfThis cheatsheet covers materials first two problem sets EDAV course fall 2022. Thus, types graphs coding method can added cheatsheet make useful R programming EDAV purposes. Hope cheatsheet can help learning, looking forward valuable advices!","code":""},{"path":"preprocessing-and-visualization-of-time-series-data.html","id":"preprocessing-and-visualization-of-time-series-data","chapter":"11 Preprocessing and Visualization of Time Series Data","heading":"11 Preprocessing and Visualization of Time Series Data","text":"Siyuan DingIn tutorial, learn visualize time series data. reaching time series data, always organized want, need preprocessing first visualize . use time series dataset Covid-19 vaccination 2020-12-14 2022-10-30 example tutorial, dataset available https://raw.githubusercontent.com/govex/COVID-19/master/data_tables/vaccine_data/us_data/time_series/time_series_covid19_vaccine_doses_admin_US.csv goal visualize relationship vaccinated doses state 2022, 2022-01-01.use three packages tutorial: dplyr, lubridate tidyr manipulate dataset preprocessing, ggplot2 visualization.","code":"\n# The packages can be installed by command: install.packages()\nlibrary(dplyr) \nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(tidyr)"},{"path":"preprocessing-and-visualization-of-time-series-data.html","id":"preprocess-on-a-time-series-data","chapter":"11 Preprocessing and Visualization of Time Series Data","heading":"11.1 Preprocess on a Time Series Data","text":"part, first work transforming original data downloaded online data frame work . look data see whether problem data points discipline Time Series Data. Finally deal missing values. preprocessings done, data good visualize analyze.","code":""},{"path":"preprocessing-and-visualization-of-time-series-data.html","id":"transform-dataset","chapter":"11 Preprocessing and Visualization of Time Series Data","heading":"11.1.1 Transform DataSet","text":"first load get overall look dataset, find data 61 rows 698 columns. visualize relationship vaccinated doses state, need three things: state name, state population state vaccination population day. achieve , can use select dplyr package r. focus data 2022 example .Now, table 305 columns, make dataframe works better, woule like four columns Province_State, Population, Date, Vaccination_Doses Date comes colnames table Vaccination_Doses number population state date comes original entries date columns. achieve , can temporarily ignore Population column since identical state, can just full join later work vaccination population first. duplicate state name number dates times, build matrix store value vaccination dose state day extracting original dataset using subset dplyr transform dataframe putting together.Now transformed dataframe vaccinated doses, can full join Population state. province available population data, deal , can use drop_na function tidyr. functino let us drop rows according column na values.time, got transformed dataframe information needed, remember, time series dataset, need careful Date column! must check whether entries date type need sort date visualization date type like string.found data type date ! Now, need transform date type using lubridate package. lubridate, can manipulate dates easily, many functions packages. string daymonthyear, example “12032000”, can use dmy() return date format “2000-03-12”; Similarly, string monthdayyear format, can use mdy(), can use ymd() data yearmonthday format. Just remember m represents month, d represents day, y represents year able find correct function need. example case, entries Date now string yearmonthday format, use ymd() . use function, first need remove ‘X’ character beginning date, can achieve substring function.can double check data type, find date format now. dataframe transformed good use.","code":"\n# load data\nvaccination_all <- read.csv(\"https://raw.githubusercontent.com/govex/COVID-19/master/data_tables/vaccine_data/us_data/time_series/time_series_covid19_vaccine_doses_admin_US.csv\")\ncolnames(vaccination_all)[1:15]##  [1] \"UID\"            \"iso2\"           \"iso3\"           \"code3\"         \n##  [5] \"FIPS\"           \"Admin2\"         \"Province_State\" \"Country_Region\"\n##  [9] \"Lat\"            \"Long_\"          \"Combined_Key\"   \"Population\"    \n## [13] \"X2020.12.14\"    \"X2020.12.15\"    \"X2020.12.16\"\ncolnames(vaccination_all)[(ncol(vaccination_all)-5):ncol(vaccination_all)]## [1] \"X2022.10.26\" \"X2022.10.27\" \"X2022.10.28\" \"X2022.10.29\" \"X2022.10.30\"\n## [6] \"X2022.10.31\"\nvaccination_df <- vaccination_all %>% select(Province_State, Population, `X2022.01.01`:tail(names(vaccination_all),1))\ncolnames(vaccination_df)[1:15]##  [1] \"Province_State\" \"Population\"     \"X2022.01.01\"    \"X2022.01.02\"   \n##  [5] \"X2022.01.03\"    \"X2022.01.04\"    \"X2022.01.05\"    \"X2022.01.06\"   \n##  [9] \"X2022.01.07\"    \"X2022.01.08\"    \"X2022.01.09\"    \"X2022.01.10\"   \n## [13] \"X2022.01.11\"    \"X2022.01.12\"    \"X2022.01.13\"\ncolnames(vaccination_df)[(ncol(vaccination_df)-5):ncol(vaccination_df)]## [1] \"X2022.10.26\" \"X2022.10.27\" \"X2022.10.28\" \"X2022.10.29\" \"X2022.10.30\"\n## [6] \"X2022.10.31\"\nvaccination_df <- vaccination_df[,-2]\n# Find number of States\nstate <- vaccination_df$Province_State\nState_num <- length(state)\n# Find number of Days\ndate <- colnames(vaccination_df)[c(-1)]\ntime_window <- dim(vaccination_df)[2]-1\n# Then in the transformed dataframe, each state should occur for time_window times\nState <- rep(state, each = time_window)\n# Then in the transformed dataframe, each date should occur for State_num times\nDate <- rep(date, State_num)\n# Build a matrix to contain the vaccination doses\nvac_matrix <- matrix()\n# We select the daily vaccination doses for each state and store them in a Matrix\nfor (i in 1:State_num){\n  vac_matrix <- rbind(vac_matrix,matrix(unlist(vaccination_df%>%subset(Province_State==state[i]))[-1]))\n}\n# Drop the first column, which is NA\nvac_matrix <- vac_matrix[2:length(vac_matrix)]\n# Get the transformed dataset\nVac_DF <- cbind.data.frame(State, Date, vac_matrix)\ncolnames(Vac_DF) <- c(\"State\", \"Date\", \"Vaccinated Doses\")\nVac_DF$`Vaccinated Doses` = as.numeric(Vac_DF$`Vaccinated Doses`)\nhead(Vac_DF)##     State        Date Vaccinated Doses\n## 1 Alabama X2022.01.01          5624234\n## 2 Alabama X2022.01.02          5624234\n## 3 Alabama X2022.01.03          5624234\n## 4 Alabama X2022.01.04          5678299\n## 5 Alabama X2022.01.05          5681793\n## 6 Alabama X2022.01.06          5695747\nstate_pop <- vaccination_all %>% select(Province_State, Population)\nVac_DF <- Vac_DF %>% full_join(state_pop, by = c (\"State\" = \"Province_State\"))\nVac_DF <- Vac_DF %>% drop_na(Population)\nhead(Vac_DF)##     State        Date Vaccinated Doses Population\n## 1 Alabama X2022.01.01          5624234    4903185\n## 2 Alabama X2022.01.02          5624234    4903185\n## 3 Alabama X2022.01.03          5624234    4903185\n## 4 Alabama X2022.01.04          5678299    4903185\n## 5 Alabama X2022.01.05          5681793    4903185\n## 6 Alabama X2022.01.06          5695747    4903185\nstate <- unique(Vac_DF$State)\nState_num <- length(state)\ndate <- unique(Vac_DF$Date)\ntime_window <- length(date)\n# Check data type of the Date column\nclass(Vac_DF$Date)## [1] \"character\"\n# We first remove the 'X' before the date\nVac_DF$Date <- substring(Vac_DF$Date,2)\nVac_DF$Date <- ymd(Vac_DF$Date )\nhead(Vac_DF)##     State       Date Vaccinated Doses Population\n## 1 Alabama 2022-01-01          5624234    4903185\n## 2 Alabama 2022-01-02          5624234    4903185\n## 3 Alabama 2022-01-03          5624234    4903185\n## 4 Alabama 2022-01-04          5678299    4903185\n## 5 Alabama 2022-01-05          5681793    4903185\n## 6 Alabama 2022-01-06          5695747    4903185\nclass(Vac_DF$Date)## [1] \"Date\""},{"path":"preprocessing-and-visualization-of-time-series-data.html","id":"deal-with-missing-values","chapter":"11 Preprocessing and Visualization of Time Series Data","heading":"11.1.2 Deal with Missing Values","text":"moving , first check missing values.found missing values, need worry missing values case.missing values example case, two choices, either impute missing values remove . make future analysis accurate, better try impute . Since data time series data, vaccinated doses day 1 greater doses day 2, conversely, vaccinated doses day 2 less doses day 1, impute missing value closest non missing value, achieve fill function tidyr package. function impute missing value previous next value, argument .direction can define direction impute.Since missing values, can move deal problematic data.","code":"\nsum(is.na(Vac_DF$`Vaccinated Doses`))## [1] 0"},{"path":"preprocessing-and-visualization-of-time-series-data.html","id":"deal-with-problematic-data-points","chapter":"11 Preprocessing and Visualization of Time Series Data","heading":"11.1.3 Deal with Problematic Data Points","text":"moving visualization analysis, need careful whether data cumulative ! data cumulative, value monotonically, example case, since data vaccination doses state day, vaccinated doses day 2 less value day 1. need check whether data day 2 smaller value day 1, assign value day 2 value day 1.Now finished preprocessings. brief conclusion, find dataset online, first load transform usable dataframe. usually requires functions dplyr working time series data, also need functions lubridate make date date type variable instead character can order later visualization. imputing missing values, tidyr popular package use since impute missing value value nearest date. need look data points, deal problematic data points according dataset , example case, working vaccinated doses along time, must monotonically increasing variable. finishing steps, move visualizing data.","code":"\nfor (i in 1:length(state)){\n  for (j in 2:time_window){\n    if ((Vac_DF %>% subset(State == state[i]) %>% select(`Vaccinated Doses`))[j,] < \n        (Vac_DF %>% subset(State == state[i]) %>% select(`Vaccinated Doses`))[j-1,]){\n      Vac_DF[\"Vaccinated Doses\"][Vac_DF[\"State\"] == state[i]][j] <- Vac_DF[\"Vaccinated Doses\"][Vac_DF[\"State\"] == state[i]][j-1]\n    }\n  }\n}"},{"path":"preprocessing-and-visualization-of-time-series-data.html","id":"visualize-a-time-series-data","chapter":"11 Preprocessing and Visualization of Time Series Data","heading":"11.2 Visualize a Time Series Data","text":"visualize time series data, mainly focus trend. want see data changes time, like geom_line ggplot2 show changes time state.graph give us much informaiton tell state, make graph varries color according states command color = State.graph looks much better now can find line corresponded state color. can easily find state highest vaccinated doses California. since California large vaccinated doses, range plot great make trend clear. may want check states’ population. get deeper insight, can visualize population state using geom_bar.bar plot give much insights without ordering, order easily find populatioin order state, can order plot using factor().ordering barplot, find California highest population among states result vaccinated doses greatest amount California give much information California great population . order get deeper insights, can visualize vaccinated doses rate, divide vaccinated doses population. Since like see trends time difference state, use geom_line() color state.Now can get better look find District Columbia highest vaccinated doses rate proves important us look vaccinated doses rate instead absolute vaccinated doses since population affect results.Now got great visualization time series data.","code":"\nggplot(data = Vac_DF, mapping = aes(x = Date, y = `Vaccinated Doses`, group = State)) +\n  geom_line() +\n  ggtitle(\"Vaccinated Doses V.S. Date\")\nggplot(data = Vac_DF, mapping = aes(x = Date, y = `Vaccinated Doses`, group = State, color = State)) +\n  geom_line() +\n  ggtitle(\"Vaccinated Doses V.S. Date\")\nggplot(data = Vac_DF, mapping = aes(x= Population, y = State)) + \n  geom_bar(stat=\"identity\")\norder <- unique(Vac_DF %>% select(Population, State) %>% arrange(Population) %>% mutate(State = factor(State)))\nPop_Order_DF <- Vac_DF %>% mutate(State = factor(State, levels = order$State, ordered = TRUE))\nggplot(data = Pop_Order_DF, mapping = aes(x= Population, y = State)) + \n  geom_bar(stat=\"identity\")\nVac_Rate_DF <- Vac_DF %>% mutate(`Vaccinated Doses Rate` = `Vaccinated Doses`/Population)\n\nggplot(data = Vac_Rate_DF, mapping = aes(x = Date, y = `Vaccinated Doses Rate`, group = State, color = State)) +\n  geom_line() +\n  ggtitle(\"Vaccinated Doses Rate V.S. Date\")"},{"path":"preprocessing-and-visualization-of-time-series-data.html","id":"conclusion","chapter":"11 Preprocessing and Visualization of Time Series Data","heading":"11.3 Conclusion","text":"conclusion, dealing time series data, need spend time preprocessing, including transforming date usable dataframe using dplyr tidyrpackage, dealing missing values, problematic data. transforming data, important watch date type! need date class instead character, can order visualizing, date format can converted functions lubridate package. finish theses preprocessing works, can start visualization part using ggplot2, try remove potential affecting factors order get clear look data trend time.","code":""},{"path":"how-to-use-sqldf.html","id":"how-to-use-sqldf","chapter":"12 How to use sqldf","heading":"12 How to use sqldf","text":"Conor Ryan","code":"\nlibrary(sqldf)\nlibrary(tidyverse)"},{"path":"how-to-use-sqldf.html","id":"motivation","chapter":"12 How to use sqldf","heading":"12.1 Motivation","text":"sqldf library lets work dataframes database tables, can query whatever SQL-style manipulation want, without worrying logistics managing databases. can useful various dataframe manipulations, often need preparing data visualization.reasons thought library use tutorial:Github page kind mess, official CRAN documentation particularly user-friendly.pretty cool tool think : overhead extra work, can just call SQL dataframe.option use SQL incredibly useful dealing working many languages. need quick R visualization just working Python, might easier just manipulate data via SQL rather figure exact R syntax thing.Certain data manipulation just suited SQL syntax, like complicated left joins window functions.scale data gets large memory, library offers impressive advantages. Even can load large dataset memory, slow; way faster initial manipulation (like filtering data 100-fold) library, reasonable deal resulting dataframe.approach significant improvement something like dbplyr knitr SQL engine. approach still requires manual management connections tables. Additionally, knitr hardly suited non-report-style work R. sqldf usable wider variety scenarios.","code":""},{"path":"how-to-use-sqldf.html","id":"usage","chapter":"12 How to use sqldf","heading":"12.2 Usage","text":"","code":""},{"path":"how-to-use-sqldf.html","id":"basics","chapter":"12 How to use sqldf","heading":"12.2.1 Basics","text":"’ve installed sqldf, really easy loading library writing SQL:create database, load data table, cleanup table. package handled behind scenes.can realistic, basic manipulation. R might :SQL can :","code":"\nsqldf('select * from iris') |> head()##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\niris |>\n  filter(Petal.Length > 2.0) |>\n  mutate(Sepal_Product = Sepal.Length * Sepal.Width) |>\n  group_by(Species) |>\n  summarize(mean_sepal_product=mean(Sepal_Product)) |>\n  head()## # A tibble: 2 × 2\n##   Species    mean_sepal_product\n##   <fct>                   <dbl>\n## 1 versicolor               16.5\n## 2 virginica                19.7\nsqldf('\n  select Species, avg(`Sepal.Length` * `Sepal.Width`) as mean_sepal_product\n  from iris\n  where `Petal.Length` > 2.0\n  group by 1\n') |>\n  head()##      Species mean_sepal_product\n## 1 versicolor            16.5262\n## 2  virginica            19.6846"},{"path":"how-to-use-sqldf.html","id":"more-advanced-sql-tasks","chapter":"12 How to use sqldf","heading":"12.2.2 More advanced SQL tasks","text":"library becomes powerful use things SQL uniquely good . example, although simple join matching column condition relatively easy R (Python), following sort condition annoying accomplish:Similarly, window functions become far accessible package:unique tasks might even preferable just use SQL rather R dataframe manipulation. fine; every tool can everything prefectly – SQL excels specific things.","code":"\nsqldf('\n  select a.Species, b.Species, avg(a.`Sepal.Width`) as `a.Width.Avg`\n  from iris a\n  join iris b\n    on a.species != b.species\n    and a.`Sepal.Length` > b.`Sepal.Length`\n    and a.`Sepal.Width` < b.`Sepal.Width`\n  group by 1,2\n') |>\n  head()##      Species    Species a.Width.Avg\n## 1 versicolor     setosa    2.764037\n## 2 versicolor  virginica    2.738889\n## 3  virginica     setosa    2.901931\n## 4  virginica versicolor    2.737284\nsqldf('\n  select Species, avg(`Sepal.Length`) over (partition by Species order by `Sepal.Length` desc rows between unbounded preceding and current row) as running_mean\n  from iris\n') |>\n  head()##   Species running_mean\n## 1  setosa     5.800000\n## 2  setosa     5.750000\n## 3  setosa     5.733333\n## 4  setosa     5.675000\n## 5  setosa     5.640000\n## 6  setosa     5.600000"},{"path":"how-to-use-sqldf.html","id":"alternate-data-sources","chapter":"12 How to use sqldf","heading":"12.2.3 Alternate data sources","text":"also don’t already dataframe -memory use library. Suppose iris .csv machine:wanted immediately get memory rows filtered :great didn’t ever “useless” version dataframe ever code; immediately get version filtering done., data lives .csv remote host?Hopefully can see options powerful. Although iris small, sometimes data large, may want deal loading many millions rows R going filter anyway. example later Performance section.","code":"\n# disabled because we were asked to not write any data\nwrite.table(iris, 'iris.csv', sep = \",\", quote = FALSE, row.names = FALSE)\n# disabled because we were asked to not write any data\nread.csv.sql('iris.csv',  sql = 'select * from file where \"Petal.Length\" > 2.0') |>\n  head()\nread.csv.sql(\n  'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv',\n  sql = 'select * from file where \"Petal.Length\" > 2.0'\n) |>\n  head()##   sepal.length sepal.width petal.length petal.width      variety\n## 1          7.0         3.2          4.7         1.4 \"Versicolor\"\n## 2          6.4         3.2          4.5         1.5 \"Versicolor\"\n## 3          6.9         3.1          4.9         1.5 \"Versicolor\"\n## 4          5.5         2.3          4.0         1.3 \"Versicolor\"\n## 5          6.5         2.8          4.6         1.5 \"Versicolor\"\n## 6          5.7         2.8          4.5         1.3 \"Versicolor\""},{"path":"how-to-use-sqldf.html","id":"advanced-database-usage","chapter":"12 How to use sqldf","heading":"12.2.4 Advanced database usage","text":"hood, sqldf actually loads dataframe temporary database table. want, can also manage database intelligently. contrived use case, worth knowing. Suppose ’re dealing lot data plan two subsequent queries. better read dataframe table reuse table. can accomplished via:can also just pass database administrative command function well. example, manage entire database (create new schemas, tables, adjust permissions) really wanted . Although appropriate tool might worth considering.","code":"\nsqldf() # keep iris as a table in the db## <SQLiteConnection>\n##   Path: :memory:\n##   Extensions: TRUE\nsqldf('select * from iris') |> # iris now loaded as a table. can reuse it.\n  head()##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa\nsqldf() # connection closed and iris table deleted## NULL"},{"path":"how-to-use-sqldf.html","id":"performance","chapter":"12 How to use sqldf","heading":"12.3 Performance","text":"Certain tasks actually end optimal done sqldf. example, following arbitrarily large join, fans nearly billion rows, took roughly 30 seconds laptop finish. (Although task nonsense, real data, one may come across use case actually needs something similar.)following R equivalent, third ‘join’, took longer four took SQL. preserve computer, attempt fourth merge (commented ).library also becomes helpful dealing large datasets disk. example, arbitrary .csv ~600MB (include file project, feel free try large file). require load entire file R first, finished 30 seconds.worthwhile improvement; R equivalent completed 45 seconds.difference becomes meaningful dataset’s size increases relative machine’s memory. file several GB, preprocessing temporary database table becomes increasingly efficient relative pure R. observed marginal version optimization . functionality especially useful know never need refer back full file (meaning use e.g. transformed version ).","code":"\nsqldf('\n  select count(*)\n  from iris a\n  join iris b using (species)\n  join iris c using (species)\n  join iris d using (species)\n  join iris e using (species)\n')##    count(*)\n## 1 937500000\nmerge(iris, iris, by=\"Species\") |>\n  merge(iris, by=\"Species\") |>\n  merge(iris, by=\"Species\") |>\n  #merge(iris, by=\"Species\") |>\n  nrow()## [1] 18750000\n# disabled because I cannot provide this (intentionally) large file\nread.csv.sql(\n  '~/Downloads/star2002-1.csv',\n  sql='select `X1`, avg(`X807`) from file where `X4518` > 5500 group by 1'\n) |>\n  head()\n# disabled because I cannot provide this (intentionally) large file\nread.csv(file = '~/Downloads/star2002-1.csv') |>\n  filter(X4518 > 5500) |>\n  group_by(X1) |>\n  summarize(some_avg=mean(X807)) |>\n  head()"},{"path":"how-to-use-sqldf.html","id":"combining-with-ggplot","chapter":"12 How to use sqldf","heading":"12.4 Combining with ggplot","text":"can also combine sqldf manipulations ggplot easily make visualizations. use sqldf scenarios excels , outlined , becomes powerful. infinite combinations , one simple illustrative example:","code":"\nsqldf('\n      select Species, avg(`Sepal.Width`) as avg_width\n      from iris\n      group by 1\n') |>\n  ggplot(aes(x=reorder(Species, avg_width), y=avg_width)) +\n  geom_bar(stat='identity') +\n  coord_flip() +\n  xlab('Species')"},{"path":"how-to-use-sqldf.html","id":"conclusion-1","chapter":"12 How to use sqldf","heading":"12.5 Conclusion","text":"sqldf important option available manipulating data. clear, replacement knowing use R general. One restrict using sqldf uniquely advantageous SQL-style work, don’t want deal writing perfect R. guide useful anyone new library exactly scenarios one might opt use .Personally, ’m glad chose deep dive library create guide. educational many ways, like: learning databases, understanding R can blend SQL, elucidating things R vs. SQL excel . certainly referring back document, think makes easy review exactly quickly use library, without getting --weeds nuts bolts (much existing documentation , opinion). One thing ’d like dedicate effort next time exactly replicating complex SQL commands R; knowing likely useful point, even practical right now. Finally, wish known library sooner, know sure optimize parts workflow going foward.","code":""},{"path":"how-to-use-sqldf.html","id":"references","chapter":"12 How to use sqldf","heading":"12.6 References","text":"https://github.com/ggrothendieck/sqldfhttps://cran.r-project.org/web/packages/sqldf/index.htmlhttps://www.geeksforgeeks.org/window-functions--sql/","code":""},{"path":"googlevis-in-r.html","id":"googlevis-in-r","chapter":"13 googleVis in R","heading":"13 googleVis in R","text":"Sushant Prabhu Kiyan Mohebbizadeh","code":""},{"path":"googlevis-in-r.html","id":"introducing-googlevis","chapter":"13 googleVis in R","heading":"13.1 Introducing googleVis","text":"GoogleVis package R allows users R use Google Charts API.interface R Google Charts allows users access Google Charts’ interactive charts. googleVis allows users use data R data frames create Google Charts without uploading data onto Google.Demonstrating using googleVis Library - Installation Usage","code":"install.packages('googleVis')\nlibrary(googleVis)"},{"path":"googlevis-in-r.html","id":"why-use-googlevis","chapter":"13 googleVis in R","heading":"13.2 Why use googleVis ?","text":"googleVis package allows users create interactive visualizations R’s popular visualization package (ggplot) allow.Although packages work conjunction ggplot make interactive visualizations, googleVis offers holistic package allows unique interactive visualizations.using Google Charts, one able create wide variety visualizations ranging typical bar line graphs mapping timeline charts one package.visualizations created googleVis add level interest consumer due interactive layer viewers able gather specific bits information hovering clicking values visualizations. allows increased aesthetics, also information transferred viewers.","code":""},{"path":"googlevis-in-r.html","id":"googlevis-rendering-interaction","chapter":"13 googleVis in R","heading":"13.3 googleVis Rendering & Interaction","text":"output googleVis can either embedded HTML file read dynamically. visualizations often rendered online web format. Therefore, browser internet connection required view interactive version output compared ggplotFor use R, googleVis allows user render Shiny file allows preview interaction within R. used preview chart final render.googleVis package R allows users R use Google Charts API.interface R Google Charts allows users access Google Charts’ interactive charts.googleVis allows users use data R data frames create Google Charts without uploading data onto Google.","code":""},{"path":"googlevis-in-r.html","id":"basic-graphs-line-bar-combo","chapter":"13 googleVis in R","heading":"13.3.1 Basic Graphs (Line, Bar, Combo)","text":"charts best used comparisons groups. seen examples, comparisons costs owning different pets.line graph shows different variables flow within among groups. audience able determine within group trends seeing lines intersect within group. Showing trends variables lines groups allows us make comparisons among various groups clarity.organizing variables certain way, one able get sense population trends.bar column chart essentially just rotated axis. allow great group comparisons well comparisons among groups. However, charts best used -group comparisons.Combo charts great multiple variable comparisons allow user get best worlds. carefully selecting variables represented bars ones lines, user able best show relationship within groups trends population.","code":"\ndf = data.frame(pet=c('cat', 'dog', 'hamster', 'snake'),\n                food_cost_monthly=c(50, 100, 10, 40),\n                medical_cost_monthly=c(30, 60, 5, 50))\nLine <- gvisLineChart(df)\n\nBar <- gvisBarChart(df)\n\nColumn <- gvisColumnChart(df)\n\nSteppedArea <- gvisSteppedAreaChart(df, xvar=\"pet\", \n                                    yvar=c(\"food_cost_monthly\", \"medical_cost_monthly\"),\n                                    options=list(isStacked=TRUE))\n\nCombo <- gvisComboChart(df, xvar=\"pet\",\n                        yvar=c(\"food_cost_monthly\", \"medical_cost_monthly\"),\n                        options=list(seriesType=\"bars\",\n                                     series='{1: {type:\"line\"}}'))\nplot(Line)\nplot(Bar)\nplot(Column)\nplot(SteppedArea)\nplot(Combo)"},{"path":"googlevis-in-r.html","id":"googlevis-histogram-chart","chapter":"13 googleVis in R","heading":"13.3.2 googleVis Histogram Chart","text":"histogram allows users represent distribution one particular group variable showing frequency particular group variable within range. charts googleVis advantage regular histograms almost histogram allows recommends specific information regarding counts different points visualization, however, googleVis audience can look distribution access specific metrics interaction well.","code":"\ndf <- iris\nHistogram <- gvisHistogram(data.frame(Sepal_Width = df$Sepal.Width))\n\nplot(Histogram)"},{"path":"googlevis-in-r.html","id":"googlevis-alluvialsankey-chart","chapter":"13 googleVis in R","heading":"13.3.3 googleVis Alluvial/Sankey Chart","text":"Alluvial charts best show movement sample population among different variables. example movement students within school class class represented. visualization can helpful data ordinal timeline specific values. googleVis, audience exposed general trends clean looking chart well specifics graph interaction.","code":"\ndf <- data.frame(From=c(rep(\"Math\",3), rep(\"Science\", 3)),\n                    To=c(rep(c('Lunch', 'Art', 'Music'),2)),\n                    Weight=c(17,15,13,5,12,8))\n\nAlluvial <- gvisSankey(df, from=\"From\", to=\"To\", weight=\"Weight\")\n\nplot(Alluvial)"},{"path":"googlevis-in-r.html","id":"googlevis-geographic-chart","chapter":"13 googleVis in R","heading":"13.3.4 googleVis Geographic Chart","text":"Map visualizations googleVis incredibly easy create manipulate. useful comparing different geographic areas . googleVis automatically color scales values interaction allows map simple clean, get specific values hovering particular geographic area.","code":"\ndf = data.frame(country=c('US', 'CN', 'BR', 'IS', 'RU', 'TH', 'TR', 'ID', 'MX', 'IR' ),\n                incarceration_rate = c(2068800, 1690000, 811707, 478600, 471490, 309282, 291198, 266259, 220866, 189000))\n\nG <- gvisGeoChart(df, locationvar = \"country\", colorvar = \"incarceration_rate\",\n                  options=list(\n                         gvis.editor=\"Edit the Geo Chart !\"))\n\nplot(G)"},{"path":"googlevis-in-r.html","id":"googlevis-gauge-chart","chapter":"13 googleVis in R","heading":"13.3.5 googleVis Gauge Chart","text":"gauge charts interactive, however offer unique way model data always within certain range. example, temperatures, speeds, pressure, etc. chart allows quick comparison groups aesthetic value presentation.","code":"\ntemperature <- data.frame(city=c('Las Vegas', 'Los Angeles', 'Pheonix', 'Dallas', 'Houston', 'Miami'),\n                          temp=c(115, 103, 120, 110, 112, 101))\nGauge <-  gvisGauge(temperature, \n                    options=list(min=0, max=150, greenFrom=0,\n                                 greenTo=50, yellowFrom=50, yellowTo=100,\n                                 redFrom=100, redTo=150, width=400, height=300))\n\nplot(Gauge)"},{"path":"googlevis-in-r.html","id":"googlevis-tabular-chart","chapter":"13 googleVis in R","heading":"13.3.6 googleVis Tabular Chart","text":"data formatted table can paged sorted. flexible option select single rows either keyboard mouse. also powers sorting rows across dimensions columns dataset. navigation paged tabular information smooth simple.","code":"\n## Tabular Data Un-Paged\nPopulation_Tabular_Unpaged <- gvisTable(Population[1:30,],\n                                        formats=list(Population=\"#,###\",'% of World Population'='#.#%'))\n\nplot(Population_Tabular_Unpaged)\n## Tabular Data Paged\nPopulation_Tabular_paged <- gvisTable(Population[1:30,], \n                                      formats=list(Population=\"#,###\",'% of World Population'='#.#%'),\n                                      options=list(page='enable',\n                                                   height='automatic',\n                                                   width='automatic'))\n\nplot(Population_Tabular_paged)"},{"path":"googlevis-in-r.html","id":"googlevis-tree-map-chart","chapter":"13 googleVis in R","heading":"13.3.7 googleVis Tree Map Chart","text":"googleVis tree map visual representation data tree, node 0 children, 1 parent barring root node. One can specify many levels display simultaneously, optionally display deeper levels. One can move tree person left-clicks node, moves back tree person right-clicks graph.total size graph determined size elements contained graph.googleVis tree map chart captures relative sizes data categories, helps quick insight datapoints bigger contributors category. Color helps scrutinize datapoints underperforming / overperforming) compared siblings category.","code":"\nCountry_Tree <- gvisTreeMap(Regions, \"Region\", \"Parent\", \"Val\", \"Fac\", \n                     options=list(width=800, height=500, fontSize=15,\n                                  minColor='#cfe2f3',midColor='#6fa8dc',maxColor='#0b5394',\n                                  headerHeight=10,fontColor='black',showScale=TRUE))\n\nplot(Country_Tree)"},{"path":"googlevis-in-r.html","id":"googlevis-annotation-chart","chapter":"13 googleVis in R","heading":"13.3.8 googleVis Annotation Chart","text":"Annotation charts useful, interactive time series like line charts enable annotations.annotated charts leveraged highlight specific data value-add contextual notes within visualization.answer “?” kind questions, well defined annotations highlight significance data chart, keen detail textual description / annotation.One can also slice interactive timeline chart look snapshot data aesthetically pleasing also provides great detail insights within visualization. annotation charts SVG (scalable vector graphics) /VML (vector graphics rendering ).","code":"\nStock_Annotation <- gvisAnnotationChart(Stock, datevar=\"Date\",numvar=\"Value\", idvar=\"Device\", titlevar=\"Title\",\n                                        annotationvar=\"Annotation\",\n                                        options=list(displayAnnotations=TRUE,\n                                        chart=\"{chartArea:{backgroundColor:'#ebf0f7'}}\",\n                                        legendPosition='newRow',width=800, height=450,\n                                        scaleColumns='[0,1]',scaleType='allmaximized'))\n\nplot(Stock_Annotation)"},{"path":"googlevis-in-r.html","id":"googlevis-calendar-chart","chapter":"13 googleVis in R","heading":"13.3.9 googleVis Calendar Chart","text":"googleVis calendar chart definitive visualization can used show activity course longer duration time, example months years decades. One can illustrate variation 1 quantity depending days given week, trends timeline period.calendar charts demonstrate data records, events, daily, weekly, monthly, yearly calendar. highly interactive one can view value hovering particular time entire timeperiod.","code":"\nCalendar_Temp <- gvisCalendar(Cairo, datevar=\"Date\", numvar=\"Temp\",\n                    options=list(title=\"Cairo's variation in Daily\n                                 temperature\",height=400,width=1000,\n                                 calendar=\"{yearLabel: { fontName:'sans-serif',\n                                 fontSize: 20, color: 'black', bold: true},\n                                 cellSize: 10,cellColor:{stroke: 'black', strokeOpacity: 0.2},\n                                 focusedCellColor: {stroke:'red'}}\"), chartid=\"Calendar\")\n\nplot(Calendar_Temp)"},{"path":"googlevis-in-r.html","id":"googlevis-timeline-chart","chapter":"13 googleVis in R","heading":"13.3.10 googleVis Timeline Chart","text":"googleVis Timeline chart great fascinating way visualizing different dates / events. example, showing duration Presidents & Vice Presidents / Sessions Congress timeline period. exact times durations given one interactively hovers bars.timeline charts versatile visuals illustrating sequence events chronologically. provides amazing aid conceptualize event sequences / processes gain valuable insights, sometimes maybe summarize historical events, time frame minutes, hours, years datewise.","code":"\nPosition_Timeline_Data <- data.frame(Position=c(rep(\"President\", 4), rep(\"Vice\", 4)),\n                    Name=c(\"William Clinton\",\"George Bush\", \"Barack Obama\", \"   Donald Trump\",\n                          \" Albert Gore\",\"Dick Cheney\", \"Biden, Jr.\", \"Michael Pence\"),\n                    start=as.Date(x=rep(c(\"1993-01-20\",\"2001-01-20\", \"2009-01-20\",\"2017-01-20\"),2)),\n                    end=as.Date(x=rep(c(\"2001-01-20\",\"2009-01-20\", \"2017-01-20\", \"2021-01-20\"),2)))\n\nTimeline <- gvisTimeline(data=Position_Timeline_Data, \n                         rowlabel=\"Name\",\n                         barlabel=\"Position\",\n                         start=\"start\", \n                         end=\"end\",\n                         options=list(timeline=\"{groupByRowLabel:false}\",\n                                      backgroundColor='#e3f4ff', \n                                      height=400,colors=\"['#0e407d', '#78b2ff', '#3737ab']\"))\n\nplot(Timeline)"},{"path":"googlevis-in-r.html","id":"googlevis-gantt-chart","chapter":"13 googleVis in R","heading":"13.3.11 googleVis Gantt Chart","text":"googleVis Gantt charts help teams plan work around deadlines allocate resources efficiently.Project planners also leverage Gantt charts maintain bird’s eye high level view projects track . depict relationship start end dates tasks, milestones, dependent tasks entire timeline project. Gantt chart illustrates breakdown project component tasks effectively.","code":"\ndaysToMilliseconds <- function(days){days * 24 * 60 * 60 * 1000}\ndat <- data.frame(taskID = c(\"PS\", \"EDA\", \"R\", \"ML\", \"DP\"),\n                 taskName = c(\"Identify Problem Statement\", \"EDA Analysis\", \"Research\",\n                              \"Machine Learning Modelling\", \"Data Preprocessing\"),\n                 resource = c(NA, \"write\", \"write\", \"complete\", \"write\"),\n                 start = c(as.Date(\"2022-10-01\"), NA, as.Date(\"2022-10-02\"), as.Date(\"2022-10-08\"), NA),\n                 end = as.Date(c(\"2022-10-04\", \"2022-10-08\", \"2022-10-08\",\n                                 \"2022-10-13\", \"2022-10-05\")),\n                 duration = c(NA, daysToMilliseconds(c(3, 1, 1, 1))),\n                 percentComplete = c(100, 25, 20, 0, 100),\n                 dependencies = c(NA, \"PS, DP\", NA,\n                 \"EDA\", \"PS\"))\n\nGantt_Tasks <- gvisGantt(dat, taskID = \"taskID\",taskName = \"taskName\",resource = \"resource\",\n                         start = \"start\",end = \"end\",duration = \"duration\",percentComplete = \"percentComplete\",\n                         dependencies = \"dependencies\",\n                         options = list(height = 300,\n                         gantt = \"{criticalPathEnabled:true,innerGridHorizLine: {\n                         stroke: '#e3f4ff',strokeWidth: 2},innerGridTrack: {fill: '#e8f3fa'},innerGridDarkTrack:\n                         {fill: '#c7e9ff'},labelStyle: {fontName: 'sans-serif',fontSize: 16}}\"))\n\nplot(Gantt_Tasks)"},{"path":"googlevis-in-r.html","id":"googlevis-merging-charts","chapter":"13 googleVis in R","heading":"13.3.12 googleVis Merging Charts","text":"googleVis Merge chart provides flexibility merging two gvis-objects, either next one gvis-object. objects arranged HTML table format.multiples charts view allows split individual charts Bar, Column, Line Geographic, Tabular etc. charts multiple charts, separated. numerous use cases like showing product sales per region providing information . gives lot flexibility report creation delivery aesthetically.","code":"\nGeographic <- gvisGeoChart(Exports,\n                           locationvar=\"Country\",colorvar=\"Profit\",\n                           options=list(width=400, height=200))\n\nTabular <- gvisTable(Exports,\n                     options=list(width=400, height=400))\n\nMerged_Charts <- gvisMerge(Geographic, Tabular, horizontal=FALSE, tableOptions=\"bgcolor=\\\"#7cdeb5\\\"\")\n\nplot(Merged_Charts)"},{"path":"googlevis-in-r.html","id":"use-googlevis-in-rstudio","chapter":"13 googleVis in R","heading":"13.4 Use googleVis in RStudio","text":"Using googleVis RStudio straightforward. default, RStudio renders charts new webpage -hand, view within RStudio,\n> View RStudio Viewer just use view locallyTo Knit Rmd Markdown file HTML, perform following command set Chunk option results asis {r ChartExample, results='asis', tidy=FALSE} plot(Chart, 'chart')","code":"plot(Chart)plot(Chart, browser=rstudioapi::viewer)"},{"path":"googlevis-in-r.html","id":"googlevis-references","chapter":"13 googleVis in R","heading":"13.4.1 googleVis References","text":"DocumentationGoogle ChartsDemoPaperCRAN-Stable VersionThank learning googleVis us !","code":""},{"path":"ten-interview-questions-and-answers.html","id":"ten-interview-questions-and-answers","chapter":"15 Ten interview questions and answers","heading":"15 Ten interview questions and answers","text":"Mengsu Alan Yang Zhe Wang","code":""},{"path":"ten-interview-questions-and-answers.html","id":"forward","chapter":"15 Ten interview questions and answers","heading":"15.1 Forward","text":"following cheatsheet created help fellow classmates internship search current strong-headwind job market environment.\nDon’t give ! can ! Happy hunting.","code":""},{"path":"ten-interview-questions-and-answers.html","id":"questions-and-answers","chapter":"15 Ten interview questions and answers","heading":"15.2 Questions and Answers","text":"","code":""},{"path":"ten-interview-questions-and-answers.html","id":"q1.-what-is-the-difference-between-r-and-python","chapter":"15 Ten interview questions and answers","heading":"15.2.1 Q1. What is the difference between R and Python?","text":"Answer: model building Data Science libraries similar comparable.\nModel Interpretability: R better model interpretability compared python (easier humans understand, important reporting management).\nProduction: Python programming good production, R falls short.\nCommunity Support: R better community support Python.\nData Visualization: R better data visualization libraries python.\nLearning curve: learning curve python steep R, R higher technical barrier entry.","code":""},{"path":"ten-interview-questions-and-answers.html","id":"q2.-what-are-r-packages","chapter":"15 Ten interview questions and answers","heading":"15.2.2 Q2. What are R packages?","text":"Answer: Packages collections data, functions, documentation extends capabilities base R [1]. 10,000 packages stored CRAN repository number still increasing [3]! Packages ggplot2, tibble, tidyr, dplyr part opinionated collection known “tidyverse.” One can install package calling install.packages() name package quotes argument function.","code":""},{"path":"ten-interview-questions-and-answers.html","id":"q3.-what-are-the-advantages-of-using-r","chapter":"15 Ten interview questions and answers","heading":"15.2.3 Q3. What are the advantages of using R?","text":"Answer: One strength R lies fact open source, therefore freely available distribute. R support data wrangling needs able create high quality highly manipulatible graphs plots ggplot2. R also platform independent highly compatible [2] runs operating systems. language great statistics lot Statistician buy-therefore great community support. needed, R also capable supporting Machine Learning operations.","code":""},{"path":"ten-interview-questions-and-answers.html","id":"q4.-what-are-the-disadvantages-of-using-r","chapter":"15 Ten interview questions and answers","heading":"15.2.4 Q4. What are the disadvantages of using R?","text":"Answer: beginners, R complication language steep learning curve. lacks standard GUI RStudio must used, inferior Python Jupyter Notebooks organization work flow. R good big data; consumes high memory slower run time Python MATLAB [3]. R falls short security language basic security measures. Many functionalities spread across many different packages, inconsistent quality, functionality, documentation.","code":""},{"path":"ten-interview-questions-and-answers.html","id":"q5.-what-is-the-difference-between-matrix-and-data-frames","chapter":"15 Ten interview questions and answers","heading":"15.2.5 Q5. What is the difference between matrix and data frames?","text":"Answer: data structure special way organizing data computer can used effectively. idea reduce spatial temporal complexity different tasks. two important data structures R Matrix Dataframe, look differ nature.matrix R –\nhomogeneous collection data sets arranged two-dimensional rectangular organization. *n array similar data types. created using vector input. fixed number rows columns. can perform many arithmetic operations R matrices, addition, subtraction, multiplication, division.Dataframes R –\nused store data tables. can contain multiple data types multiple columns called fields. ’s list equal length vectors. ’s generalized form matrix. ’s like table Excel worksheet. column row names. Row names unique empty columns. data stored must number, character, factor type. DataFrame heterogeneous.","code":""},{"path":"ten-interview-questions-and-answers.html","id":"q6.-what-is-the-difference-between-library-and-require","chapter":"15 Ten interview questions and answers","heading":"15.2.6 Q6. What is the difference between library() and require()?","text":"Answer: library() require() can used attach load installed additional packages. Installed packages identified help “DESCRPTION” file contains Build:field. name package needs loaded using library() require() must match name package’s “DESCRPTION” file.require() designed used inside functions gives warning message returns logical value, FALSE requested package found TRUE \npackage loaded.library() default returns error requested package exist.","code":""},{"path":"ten-interview-questions-and-answers.html","id":"q7.-what-types-of-data-files-can-be-read-and-exported-in-r","chapter":"15 Ten interview questions and answers","heading":"15.2.7 Q7. What types of data files can be read and exported in R?","text":"Answer: Data import output R programming means can read data external files, write data external files, can access files outside R environment. File formats like CSV, XML, xlsx, JSON, web data like HTML tables can imported R environment read manipulated data analysis [4]; data present R environment can stored external files file formats.","code":""},{"path":"ten-interview-questions-and-answers.html","id":"q8.-how-many-data-structures-does-r-have","chapter":"15 Ten interview questions and answers","heading":"15.2.8 Q8. How many data structures does R have?","text":"Answer: R six types basic data structures. can organize data structures according dimensions(1d, 2d, nd). can also classify homogeneous heterogeneous (can contents different types ).VectorListMatrixData frameArrayFactor","code":""},{"path":"ten-interview-questions-and-answers.html","id":"q9.-what-is-the-difference-between-pivot_wider-and-pivot_longer","chapter":"15 Ten interview questions and answers","heading":"15.2.9 Q9. What is the difference between pivot_wider() and pivot_longer()?","text":"Answer: pivot_longer() makes datasets longer vertically increasing number rows decreasing number columns; every row becomes observation. Length relative term, can say (e.g.) dataset longer dataset B. pivot_longer() commonly needed tidy wild-caught datasets often optimize ease data entry ease comparison rather ease analysis.pivot_wider() opposite pivot_longer(): makes dataset wider increasing number columns decreasing number rows. ’s relatively rare need pivot_wider() make tidy data, ’s often useful creating summary tables presentation, data format needed tools.","code":""},{"path":"ten-interview-questions-and-answers.html","id":"q10.-why-do-people-use-ggplot2","chapter":"15 Ten interview questions and answers","heading":"15.2.10 Q10. Why do people use ggplot2?","text":"Answer: ggplot2 plotting package provides helpful commands create complex plots data data frame. provides programmatic interface specifying variables plot, displayed, general visual properties following Grammar Graphics. Therefore, need minimal changes underlying data change decide change bar plot scatterplot. helps creating publication quality plots minimal amounts adjustments tweaking.","code":""},{"path":"ten-interview-questions-and-answers.html","id":"references-1","chapter":"15 Ten interview questions and answers","heading":"15.3 References","text":"[1] Wickham, Hadley, Garrett Grolemund. R Data Science: Import, Tidy, Transform, Visualize Model Data, O’Reilly, Pozostate, 2017.[2] Intellipaaat. “R Programming Interview Questions.” YouTube, 3 Jan. 2021, https://www.youtube.com/watch?v=lyFDNkbsQuE&ab_channel=Intellipaat.[3] Simplilearn. “R: Overview, Applications R Used .” Simplilearn.com, Simplilearn, 3 Oct. 2022, https://www.simplilearn.com/--r-article.[4] “R Programming Language - Introduction.” GeeksforGeeks, 15 Aug. 2021, https://www.geeksforgeeks.org/r-programming-language-introduction/.","code":""},{"path":"benford-case-study.html","id":"benford-case-study","chapter":"17 Benford Case Study","heading":"17 Benford Case Study","text":"Abhiram Gaddam, Devan Samant","code":"\nlibrary(benford.analysis)  #install.packages(\"benford.analysis\")\nlibrary(dplyr)\nlibrary(plotly)\nlibrary(tidyverse)"},{"path":"benford-case-study.html","id":"contents","chapter":"17 Benford Case Study","heading":"17.1 Contents","text":"tutorial, introduce numeric property called Benford’s Law illustrate applications fraud detection. using benford_analysis package R along example case study.Sections:IntroductionBenford.Analysis PackageRandomized Data Case StudyConclusionSources","code":""},{"path":"benford-case-study.html","id":"introduction","chapter":"17 Benford Case Study","heading":"17.2 Introduction","text":"niche area consulting industry called forensic analytics analysts try identify risks quantify wrongdoing using array statistical data techniques. example, imagine whistleblower notifies company’s general counsel collusion sales finance representatives artificially create invoices. company may hire forensic analysts extract determine happening. many quantitative qualitative methods perform concluding anything need specific context project. One heuristic Benford’s Law.","code":""},{"path":"benford-case-study.html","id":"what-is-benfords-law","chapter":"17 Benford Case Study","heading":"17.2.1 What is Benford’s Law?","text":"Benford’s law (also known first digit law) states leading digits many data sets probably going small. example, numbers set (30%) leading digit 1, one might expect probability 11.1% (one nine digits). one, second common leading digit 2 17.5%. forth 3 onward. put simply, Benford’s law probability distribution likelihood first digit set numbers (Frunza, 2015). pattern intuitive phenomenon holds true many naturally occurring datasets (ex. height mountains around world) well man-made ones company’s general ledger.formula Benford’s Law :\n\\(P(d) = \\frac{ln(1 + \\frac{1}{d})}{ln10}\\)\n\\(d\\) leading digit (number 1 9)distribution shows expected occurrence leading digits according Benford’s Law.Benfords Law Distribution.However, caveats regarding application Benford’s Law:Benford’s Law works better larger sets data. law shown hold true data sets containing 50 100 numbers, experts believe data sets 500 numbers better suited type analysis.\n(https://www.journalofaccountancy.com/issues/2017/apr/excel--benfords-law--detect-fraud.html#:~:text=Briefly%20explained%2C%20Benford’s%20Law%20maintains,leading%20digit%20with%20decreasing%20frequency)Benford’s Law works better larger sets data. law shown hold true data sets containing 50 100 numbers, experts believe data sets 500 numbers better suited type analysis.\n(https://www.journalofaccountancy.com/issues/2017/apr/excel--benfords-law--detect-fraud.html#:~:text=Briefly%20explained%2C%20Benford’s%20Law%20maintains,leading%20digit%20with%20decreasing%20frequency)conform law, data set use must contain data number 1 9 equal chance occurring leading digit. Otherwise, Benford’s Law doesn’t apply. example, consider listing heights current NBA players. Since NBA players range height 5 feet 10 inches 7 feet 3 inches, player heights begin 1, 2, 3, 4, 8, 9; Clearly digits chance first digit listing, making Benford’s Law inapplicable.conform law, data set use must contain data number 1 9 equal chance occurring leading digit. Otherwise, Benford’s Law doesn’t apply. example, consider listing heights current NBA players. Since NBA players range height 5 feet 10 inches 7 feet 3 inches, player heights begin 1, 2, 3, 4, 8, 9; Clearly digits chance first digit listing, making Benford’s Law inapplicable.Benford’s Law applicable datasets, generally applicable large sets naturally occurring numbers connection like:Companies’ stock market values.Data found texts.Demographic data, including state city populations.Income tax data.Mathematical tables, like logarithms.River drainage rates.Scientific data.\n(Benford, F)","code":""},{"path":"benford-case-study.html","id":"applications-in-fraud-detection","chapter":"17 Benford Case Study","heading":"17.2.2 Applications in Fraud Detection","text":"One primary practical use Benford’s Law fraud error detection. expected large set numbers follow law, accountants, auditors, economists tax professionals benchmark normal levels particular number set . famously documented examples Benford’s Law applied towards fraud detection (Frunza, 2015):1990s, accountant named Mark Nigrini found Benford’s law can effective red-flag test fabricated tax returns. Authentic tax data usually follows Benford’s law, whereas made-returns .law used 2001 study economic data Greece, implication country may manipulated numbers join European Union.Ponzi schemes can detected using law. Unrealistic returns, purported Maddoff scam, fall far expected Benford probability distribution .","code":""},{"path":"benford-case-study.html","id":"benford.analysis-package-in-r","chapter":"17 Benford Case Study","heading":"17.3 benford.analysis package in r","text":"Benford Analysis (benford.analysis) package provides tools make easier validate data using Benford’s Law. main purpose package identify suspicious data may need verification.Documentation package can found :\nhttps://cran.r-project.org/web/packages/benford.analysis/benford.analysis.pdfYou can install package CRAN running following (uncommented):package comes 6 real datasets Mark Nigrini’s book Benford’s Law: Applications Forensic Accounting, Auditing, Fraud Detection.","code":"\n#install.packages(\"benford.analysis\")"},{"path":"benford-case-study.html","id":"example-usage-of-benford.analysis","chapter":"17 Benford Case Study","heading":"17.3.1 Example Usage of benford.analysis","text":"section give example using 189,470 records corporate payments dataset provided package.Load package dataTo validate data Benford’s law simply use function “benford” appropriate column:creates object class “Benford” results analysis using first two significant digits default.Lets plot bfd observe trends. Note running analysis using default parameters, .e., ..digits = 2. parameter can modified want analyze first digit .original data blue expected frequency according Benford’s law red.\nexample, first plot shows data tendency follow Benford’s law.\nalso clear outlier 50.package also provides helper functions investigate data. example, can easily extract observations largest discrepancies using “getSuspects” function.","code":"\ndata(corporate.payment) \n\ndf <- corporate.payment\nhead(df)##   VendorNum       Date  InvNum Amount\n## 1      2001 2010-01-02 0496J10  36.08\n## 2      2001 2010-01-02 1726J10  77.80\n## 3      2001 2010-01-02 2104J10  34.97\n## 4      2001 2010-01-02 2445J10  59.00\n## 5      2001 2010-01-02 3281J10  59.56\n## 6      2001 2010-01-02 3822J10  50.38\nbfd <- benford(df$Amount)\nbfd## \n## Benford object:\n##  \n## Data: df$Amount \n## Number of observations used = 185083 \n## Number of obs. for second order = 65504 \n## First digits analysed = 2\n## \n## Mantissa: \n## \n##    Statistic  Value\n##         Mean  0.496\n##          Var  0.092\n##  Ex.Kurtosis -1.257\n##     Skewness -0.002\n## \n## \n## The 5 largest deviations: \n## \n##   digits absolute.diff\n## 1     50       5938.25\n## 2     11       3331.98\n## 3     10       2811.92\n## 4     14       1043.68\n## 5     98        889.95\n## \n## Stats:\n## \n##  Pearson's Chi-squared test\n## \n## data:  df$Amount\n## X-squared = 32094, df = 89, p-value < 2.2e-16\n## \n## \n##  Mantissa Arc Test\n## \n## data:  df$Amount\n## L2 = 0.0039958, df = 2, p-value < 2.2e-16\n## \n## Mean Absolute Deviation (MAD): 0.002336614\n## MAD Conformity - Nigrini (2012): Nonconformity\n## Distortion Factor: -1.065467\n## \n## Remember: Real data will never conform perfectly to Benford's Law. You should not focus on p-values!\nplot(bfd)\nsuspects <- getSuspects(bfd, df)\nsuspects##        VendorNum       Date       InvNum  Amount\n##     1:      2001 2010-01-02      3822J10   50.38\n##     2:      2001 2010-01-07     100107-2 1166.29\n##     3:      2001 2010-01-08  11210084007 1171.45\n##     4:      2001 2010-01-08      1585J10   50.42\n##     5:      2001 2010-01-08      4733J10  113.34\n##    ---                                          \n## 17852:     52867 2010-07-01 270358343233   11.58\n## 17853:     52870 2010-02-01 270682253025   11.20\n## 17854:     52904 2010-06-01 271866383919   50.15\n## 17855:     52911 2010-02-01 270957401515   11.20\n## 17856:     52934 2010-02-01 271745237617   11.88"},{"path":"benford-case-study.html","id":"randomized-case-study","chapter":"17 Benford Case Study","heading":"17.4 Randomized Case Study","text":"","code":""},{"path":"benford-case-study.html","id":"baseline-data-in-the-prior-section-we-saw-that-when-data-is-manipulated-with-static-values-clearly-the-first-digit-rule-is-broken.-but-what-about-when-data-is-randomly-manipulated","chapter":"17 Benford Case Study","heading":"17.4.1 Baseline Data*\nIn the prior section we saw that when data is manipulated with static values, clearly the first digit rule is broken. But what about when data is randomly manipulated?","text":"Let us try experiment see can use Benford’s Law detect potential data manipulation bad actor randomly generated fake sales. experiment, baseline also using random data highlight point conclusion . Let us pretend company sales data comprised prices quantities items sold. code chunck sets data frame one row recorded sale number items sold set price.Now let us set see dataset exhibits expected pattern first digit.[value] sales exhibits commonality Benford’s Law exact see first digit quite 30%. However still decreasing probability leading digit. address limitation next section. now, let us try manipulating data see patterns change.","code":"\nprice <- sample(1:1e3, size = 1e5, replace=TRUE)\nquantity <- sample(1:1e4, size = 1e5, replace=TRUE)\ndf <- data.frame(price,quantity) %>% \n  mutate(value = price*quantity) %>% \n  mutate(digit = substr(as.character(value), 1, 1))\n\nhead(df)##   price quantity   value digit\n## 1   171     9692 1657332     1\n## 2   453      731  331143     3\n## 3   974     3108 3027192     3\n## 4   361     9287 3352607     3\n## 5   269     5177 1392613     1\n## 6   704     2207 1553728     1\ndf_group <- df %>% group_by(digit) %>% summarise(count = n()) %>%\n    mutate(count_percent = count/sum(count))\n\nbase_benford = data.frame(c(1,2,3,4,5,6,7,8,9), c(.31,.176,.125,.097,.079,.067,.058,.051,.046))\ncolnames(base_benford) <- c('digit','percent')\n\nggplot(data=df_group, aes(x=digit, y=count_percent, fill=\"blue\")) +\n  geom_bar(stat=\"identity\", fill='lightblue') + \n  geom_point(aes(x=base_benford$digit, y=base_benford$percent)) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(title = \"First Digit of Randomized Sales\",\n              subtitle = \"Original Data (bar) vs Expected Benford (point)\",\n              #caption = \"TBD\",\n              x = \"First Digit\", y = \"% Occurance\",\n              #tag = \"A\"\n              ) +  theme(legend.position=\"none\")"},{"path":"benford-case-study.html","id":"manipulated-data","chapter":"17 Benford Case Study","heading":"17.4.2 Manipulated Data","text":"next piece code, can pretend someone entered additional sales “randomly” adding lots relatively smaller sales 100k.can see adding sales randomly change distribution (enough added). can quantify change? Let us use benford package cacluate statistics. followingPrinting benford object creates verbose output copied main statistics two dataframes:df (original)\nStatistic Value\nMean 0.526\nVar 0.073\nEx.Kurtosis -1.048\nSkewness -0.145df (original)\nStatistic Value\nMean 0.526\nVar 0.073\nEx.Kurtosis -1.048\nSkewness -0.145df2 (manipulated)\nStatistic Value\nMean 0.65\nVar 0.07\nEx.Kurtosis -0.59\nSkewness -0.66df2 (manipulated)\nStatistic Value\nMean 0.65\nVar 0.07\nEx.Kurtosis -0.59\nSkewness -0.66If data follows Benford’s Law, expected statistics close :\nStatistic Value\nMean 0.5\nVar 0.083\nEx.Kurtosis -1.2\nSkewness 0From glance, evident statistics corresponding original df much closer expected statistics df2. particular, Ex.Kurtosis Skewness differ significantly df2 expected values. indicators set values deviate expected distribution corresponding Benford’s Law.","code":"\nvalue2 <- sample(1:1e6, size = 4e5, replace=TRUE)\ndf_extra_sales <- data.frame(0,0,value2)\ncolnames(df_extra_sales) <- c('price','quantity','value')\ndf2 <- data.frame(price,quantity) %>% \n  mutate(value = price*(quantity)) %>% \n  rbind(df_extra_sales)  %>% \n  mutate(digit = substr(as.character(value), 1, 1))\n\ndf_group2 <- df2 %>% group_by(digit) %>% summarise(count = n()) %>%\n    mutate(count_percent = count/sum(count))\n\np2 <- ggplot(data=df_group2, aes(x=digit, y=count_percent)) +\n  geom_bar(stat=\"identity\", fill='lightblue') + \n  geom_point(aes(x=base_benford$digit, y=base_benford$percent))\np2\n#gridExtra::grid.arrange(p1,p2, ncol=2)\n\ndf_group_combined <- data.frame(df_group$digit,df_group$count_percent,df_group2$count_percent) \ncolnames(df_group_combined) <- c('digit','Original','Manipulated')\ndf_group_combined <- df_group_combined %>% pivot_longer(cols=c('Original','Manipulated'))\ncolnames(df_group_combined) <- c('digit','Dataset','count_percent')\n\nggplot(data=df_group_combined, aes(x=digit, y=count_percent, fill=Dataset)) +\n  geom_bar(stat=\"identity\", position='dodge') +\n  scale_y_continuous(labels = scales::percent) +\n  labs(title = \"First Digit of Manipulated Sales\",\n              subtitle = \"Original Data vs Manipulated Data\",\n              x = \"First Digit\", y = \"% Occurance\",\n              ) +  theme(legend.position=\"bottom\")\nbfd_1 <- benford(df$value)\n#bfd_1\n\nbfd_2 <- benford(df2$value)\n#bfd_2"},{"path":"benford-case-study.html","id":"findings","chapter":"17 Benford Case Study","heading":"17.4.3 Findings","text":"show us? sets randomly generated, one conform Benford’s Law? One reason data product many random variables tends exhibit log-normal distribution fits well first digit rule. However, adding values static way, change data uniform distort decaying curve.Now important understand 1) case extreme example highlight point, 2) Benford’s Law statistics prove anything - provide guidance areas may look strange. reality, forensic testing done specific segments accounts, people interviewed, systems logs analyzed, etc. Similarly, even Benford’s Law holds true, mean fraud; bad actor understands fraud detection methods likely hide better.","code":""},{"path":"benford-case-study.html","id":"conclusion-2","chapter":"17 Benford Case Study","heading":"17.5 Conclusion","text":"important thing note Benford’s law strict mathematical proof, simply heuristic. broad guideline helps investigation large data sets see conform observed trends. feature dataset conforms Benford’s Law proof validity vice versa. reason, Benford analysis usually conducted primary investigatory exercise, following thorough investigation described previous section conducted.","code":""},{"path":"benford-case-study.html","id":"sources","chapter":"17 Benford Case Study","heading":"17.6 Sources","text":"Benford, F. “Law Anomalous Numbers,” Proceedings American Philosophical Society, 78, 551–572. 1938.https://cran.r-project.org/web/packages/benford.analysis/benford.analysis.pdfhttps://www.statisticshowto.com/benfords-law/Frunza, M. (2015). Solving Modern Crime Financial Markets: Analytics Case Studies. Academic Press.https://www.journalofaccountancy.com/issues/2017/apr/excel--benfords-law--detect-fraud.html#:~:text=Briefly%20explained%2C%20Benford’s%20Law%20maintains,leading%20digit%20with%20decreasing%20frequency.","code":""},{"path":"github-initial-setup.html","id":"github-initial-setup","chapter":"18 Github initial setup","heading":"18 Github initial setup","text":"Joyce Robbins","code":""},{"path":"github-initial-setup.html","id":"create-new-repo","chapter":"18 Github initial setup","heading":"18.1 Create new repo","text":"Create new repository copying template: http://www.github.com/jtr13/cctemplate following instructions README.","code":""},{"path":"github-initial-setup.html","id":"pages-in-repo-settings","chapter":"18 Github initial setup","heading":"18.2 Pages in repo settings","text":"Change source gh-pagesMay trigger GHA get work","code":""},{"path":"github-initial-setup.html","id":"add-packages-to-description-file","chapter":"18 Github initial setup","heading":"18.3 Add packages to DESCRIPTION file","text":"Need better process…Downloaded submissions CourseWorksCreate DESCRIPTION file. Add add dependencies projthis::proj_update_deps()https://twitter.com/ijlyttle/status/1370776366585614342Add Imports real DESCRIPTION file.Found problematic packages looking reverse dependencies packages failed install:devtools::revdep()Also used pak::pkg_deps_tree()Problems:magickrJava dependency qdap","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"tutorial-for-pull-request-mergers","chapter":"19 Tutorial for pull request mergers","heading":"19 Tutorial for pull request mergers","text":"","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"general","chapter":"19 Tutorial for pull request mergers","heading":"19.1 General","text":"following checklist steps perform merging pull request. point, ’re sure , request review one PR leaders.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-branch","chapter":"19 Tutorial for pull request mergers","heading":"19.2 Check branch","text":"PR submitted non-main branch.PR submitted main branch, provide instructions fix problem:Close PR.Close PR.Follow instructions forgetting branch committed pushed GitHub: https://edav.info/github#fixing-mistakesFollow instructions forgetting branch committed pushed GitHub: https://edav.info/github#fixing-mistakesIf trouble 2., delete local folder project, delete fork GitHub, start .trouble 2., delete local folder project, delete fork GitHub, start .Open new PR.Open new PR.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"examine-files-that-were-added-or-modified","chapter":"19 Tutorial for pull request mergers","heading":"19.3 Examine files that were added or modified","text":"ONE .Rmd file.ONE .Rmd file.additional resources resources/<project_name>/ folder.additional resources resources/<project_name>/ folder.files root directory besides .Rmd file.files root directory besides .Rmd file.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-.rmd-filename","chapter":"19 Tutorial for pull request mergers","heading":"19.4 Check .Rmd filename","text":".Rmd filename words joined underscores, white space. (Update: need branch name.).Rmd filename can contain lowercase letters. (Otherwise filenames sort nicely repo home page.)","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-.rmd-file-contents","chapter":"19 Tutorial for pull request mergers","heading":"19.5 Check .Rmd file contents","text":"file contain YAML header --- line.second line blank, followed author name(s).first line start single hashtag #, followed single whitespace, title.additional single hashtag headers chapter. (, new chapters created.)hashtag headers followed numbers since hashtags create numbered subheadings. Correct: ## Subheading. Incorrect: ## 3. Subheading.file contains setup chunk .Rmd file, contain setup label. (bookdown render fail duplicate chunk labels.)\n.e. use {r, include=FALSE} instead {r setup, include=FALSE}.\nSee sample .RmdLinks internal files must contain resources/<project_name>/ path, : ![Test Photo](resources/sample_project/election.jpg)file contain install.packages(), write functions, setwd(), getwd().’s anything else looks odd ’re sure, assign jtr13 review explain issue.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"request-changes","chapter":"19 Tutorial for pull request mergers","heading":"19.6 Request changes","text":"problems checks listed , explain pull request merged request changes following steps:, add changes requested label pull request.job pull request done now. contributors fix requests, review either move forward merge explain changes still need made.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"steps-to-merge-the-pr","chapter":"19 Tutorial for pull request mergers","heading":"19.7 Steps to Merge the PR","text":"Go main branch project (jtr13/cc21fall1) open _bookdown.yml fileGo main branch project (jtr13/cc21fall1) open _bookdown.yml fileCopy entire rmd_files section. look something like \nrmd_files: [ 'index.Rmd', # must first chapter 'assignment.Rmd', ...., ...., ]Copy entire rmd_files section. look something like \nrmd_files: [ 'index.Rmd', # must first chapter 'assignment.Rmd', ...., ...., ]Open branch submitted PR following steps:\naccess PR branch:\n\nMake sure PR branch checking PR branch name shown (main):\nOpen branch submitted PR following steps:access PR branch:Make sure PR branch checking PR branch name shown (main):Remove rmd_files: [] section paste one copied main branch project.Remove rmd_files: [] section paste one copied main branch project.Add name new file single quotes followed comma labelled section (eg. Cheatsheets, Tutorials etc).Add name new file single quotes followed comma labelled section (eg. Cheatsheets, Tutorials etc).Save edited version.Save edited version.Come back PR.Come back PR.Merge PR.Merge PR.Click Actions tabs check whether build successful (successful build green dot front actions). PLEASE NOTE actions take complete (approximately 5-6 mins depending number files rendered), might need wait time finally check whether build successful .Click Actions tabs check whether build successful (successful build green dot front actions). PLEASE NOTE actions take complete (approximately 5-6 mins depending number files rendered), might need wait time finally check whether build successful .case build fail able understand rectify please tag one PR Assigners can review . PLEASE revert merge create new branches workflow.case build fail able understand rectify please tag one PR Assigners can review . PLEASE revert merge create new branches workflow.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"pr-leaders-only-add-part-names-to-.rmd-for-every-first-article-in-part","chapter":"19 Tutorial for pull request mergers","heading":"19.7.1 PR Leaders only: Add part names to .Rmd for every first article in part","text":"adding first chapter PART.every first article part, add chapter name top .Rmd file, propose changes. example like .\n","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"merge-pr-and-leave-a-comment","chapter":"19 Tutorial for pull request mergers","heading":"19.8 Merge PR and leave a comment","text":"Now comes final step.’re sure things correctly, assign one PR merge leaders @jtr13 review merge PR.Go back conversation tab pull requests page, example:https://github.com/jtr13/cc20/pull/23#issuecomment-728506101Leave comments congratulations 🎉 (type :tada:) click green button merge.\n","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-updated-version","chapter":"19 Tutorial for pull request mergers","heading":"19.9 Check updated version","text":"successful merge means addition file files added project merge conflicts. mean book render deploy GitHub pages without issues. merge, take 5-10 minutes GitHub Actions render book deploy updated version. Please check Action ran successfully didn’t, open issue link failed run.","code":""}]
